{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where Am I?\n",
    "\n",
    "## ODSC Masterclass Summit - San Francisco - Mar 01, 2017\n",
    "![ODSC Masterclass Summit](\thttps://s3.amazonaws.com/fluxcapacitor.com/img/odsc-masterclass-mar-01-2017-san-francisco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fcb54439-1c2c-46ce-9d92-e77df43393db"
    }
   },
   "source": [
    "# Who Am I?\n",
    "## Chris Fregly\n",
    "\n",
    "![Chris Fregly](https://s3.amazonaws.com/fluxcapacitor.com/img/fregly-300x300.png)\n",
    "\n",
    "![Chris Fregly Emoji](https://s3.amazonaws.com/fluxcapacitor.com/img/fregly-emoji-300x300.png)\n",
    "### Research Scientist @ **[PipelineIO](http://pipeline.io)** \n",
    "\n",
    "![PipelineIO](http://pipeline.io/images/pipeline-io-logo-shadow-210x186.png)\n",
    "\n",
    "### Video Series Author \"High Performance Tensorflow in Production\" @ [OReilly](http://oreilly.com) (Coming Soon)\n",
    "\n",
    "![OReilly Media](https://s3.amazonaws.com/fluxcapacitor.com/img/oreilly-logo.png)\n",
    "\n",
    "### Founder @ **[Advanced Spark and Tensorflow Meetup](http://www.meetup.com/Advanced-Spark-and-TensorFlow-Meetup/)**\n",
    "\n",
    "![Advanced Spark and Tensorflow Meetup](https://s3.amazonaws.com/fluxcapacitor.com/img/advanced-spark-tensorflow-meetup-logo-green.png)\n",
    "\n",
    "### **[Github Repo](https://github.com/fluxcapacitor/pipeline)**\n",
    "\t\n",
    "![Github Repo](https://s3.amazonaws.com/fluxcapacitor.com/img/pipeline-io-github-1000-stars.png)\n",
    "\n",
    "### **[DockerHub Repo](https://hub.docker.com/u/fluxcapacitor/)**\n",
    "\n",
    "![DockerHub](https://s3.amazonaws.com/fluxcapacitor.com/img/dockerhub-logo.png)\n",
    "\n",
    "### **[Slideshare](http://www.slideshare.net/cfregly)**\n",
    "\n",
    "![Slideshare](http://advancedspark.com/img/slideshare.png)\n",
    "\n",
    "### **[YouTube](https://www.youtube.com/playlist?list=PL7pBcJ870QHeNRBXdKirc4fdtbtbB5Xy-)**\n",
    "\n",
    "![YouTube](http://advancedspark.com/img/youtube-300x134.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Was I?\n",
    "### Software Engineer @ **Netflix**, **Databricks**, **IBM Spark Tech Center**\n",
    "\n",
    "![Netflix](http://pipeline.io/images/netflixoss-logo-white-295x55.png) \n",
    "\n",
    "![Databricks](http://pipeline.io/images/databricks-logo-350x69.png) \n",
    "\n",
    "![IBM Spark Tech Center](https://s3.amazonaws.com/fluxcapacitor.com/img/ibm-spark-logo-197x148.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "023050ea-c894-4ffe-869f-2f27f03e524a"
    }
   },
   "source": [
    "# 1. Infrastructure and Tools\n",
    "### Docker\n",
    "Images, Containers\n",
    "\n",
    "Useful Docker Image:  **[AWS + GPU + Docker + Tensorflow + Spark](https://github.com/fluxcapacitor/pipeline/wiki/AWS-GPU-TensorFlow-Docker)**\n",
    "\n",
    "![Docker](http://pipeline.io/images/docker-logo-150x126.png)\n",
    "\n",
    "### Kubernetes\n",
    "Container Orchestration Across Clusters\n",
    "\n",
    "![Kubernetes](http://pipeline.io/images/kubernetes-logo-200x171.png) \n",
    "\n",
    "### Weavescope\n",
    "Kubernetes Cluster Visualization\n",
    "\n",
    "![PipelineIO Kubernetes](https://s3.amazonaws.com/fluxcapacitor.com/img/weavescope-pipelineio.png)\n",
    "\n",
    "### Jupyter Notebooks\n",
    "What We're Using Here for Everything!\n",
    "\n",
    "![Jupyter](http://pipeline.io/images/jupyter-logo-105x106.png) \n",
    "\n",
    "### Airflow\n",
    "Invoke Any Type of Workflow on Any Type of Schedule \n",
    "\n",
    "![Airflow](https://s3.amazonaws.com/fluxcapacitor.com/img/airflow-continuous-deployment.png)\n",
    " \n",
    "### Github\n",
    "Commit New Model to Github, Airflow Workflow Triggered for Continuous Deployment \n",
    "\t\n",
    "![Github Repo](https://s3.amazonaws.com/fluxcapacitor.com/img/pipeline-io-github-1000-stars.png)\n",
    "\n",
    "### DockerHub\n",
    "Maintains Docker Images \n",
    "\n",
    "![DockerHub](https://s3.amazonaws.com/fluxcapacitor.com/img/dockerhub-logo.png)\n",
    "\n",
    "### Continuous Deployment\n",
    "Not Just for Code, Also for ML/AI Models!\n",
    "\n",
    "### Canary Release\n",
    "Deploy and Compare New Model Alongside Existing\n",
    "\n",
    "### Metrics and Dashboards\n",
    "Not Just System Metrics, ML/AI Model Prediction Metrics\n",
    "\n",
    "NetflixOSS-based\n",
    "\n",
    "Prometheus\n",
    "\n",
    "Grafana\n",
    "\n",
    "Elasticsearch\n",
    "\n",
    "### Separate Cluster Concerns\n",
    "Training/Admin Cluster\n",
    "\n",
    "Prediction Cluster\n",
    "\n",
    "### Hybrid Cloud Deployment for eXtreme High Availability (XHA)\n",
    "AWS and Google Cloud\n",
    "\n",
    "### Apache Spark\n",
    "![Spark](http://pipeline.io/images/spark-logo-150x78.png) \n",
    "\n",
    "### Tensorflow + Tensorflow Serving\n",
    "![Tensorflow](http://pipeline.io/images/tensorflow-logo-150x128.png)\n",
    "\n",
    "![Architecture](https://s3.amazonaws.com/fluxcapacitor.com/img/tensorflow-serving-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ca731c95-6e39-4db8-a51c-f467a315616d"
    }
   },
   "source": [
    "# 2. Model Deployment Bundles\n",
    "### KeyValue\n",
    "ie. Recommendations\n",
    "\n",
    "In-memory: Redis, Memcache\n",
    "\n",
    "On-disk:  Cassandra, RocksDB\n",
    "\n",
    "First-class Servable in [Tensorflow Serving](https://github.com/tensorflow/serving/tree/master/tensorflow_serving/servables)\n",
    "\n",
    "### PMML\n",
    "It's Useful and [Well-Supported](https://github.com/jpmml)\n",
    "\n",
    "Apple, Cisco, [Airbnb](http://nerds.airbnb.com/architecting-machine-learning-system-risk/), HomeAway, etc\n",
    "\n",
    "Please Don't Re-build It - Reduce Your Technical Debt!\n",
    "\n",
    "![Regression Model PMML](https://s3.amazonaws.com/fluxcapacitor.com/img/regression-model-pmml2.png)\n",
    "\n",
    "### Native Code\n",
    "Hand-coded (Python + Pickling)\n",
    "\n",
    "Generate Java Code from PMML?\n",
    "\n",
    "![Regression Model Java Codegen](https://s3.amazonaws.com/fluxcapacitor.com/img/regression-model-codegen2.png)\n",
    "\n",
    "### Tensorflow Model Exports\n",
    "[freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py): Combine Tensorflow Graph (Static) with Trained Weights (Checkpoints) into Single Deployable Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a0dd485d-6cdf-4ccc-ba0c-60b2ed06bac7"
    }
   },
   "source": [
    "# 3. Model Deployments and Rollbacks\n",
    "### Mutable\n",
    "Each New Model is Deployed to Live, Running Container\n",
    "\n",
    "### Immutable\n",
    "Each New Model is a New Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optimizing Tensorflow Models for Serving\n",
    "## Python Scripts\n",
    "[optimize_graph_for_inference.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py)\n",
    "\n",
    "[Pete Warden's Blog](https://petewarden.com/2016/12/30/rewriting-tensorflow-graphs-with-the-gtt/)\n",
    "\n",
    "[Graph Transform Tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md)\n",
    "\n",
    "\n",
    "## Compile (Tensorflow 1.0+)\n",
    "### [XLA](https://www.tensorflow.org/versions/master/experimental/xla/) Compiler\n",
    "Compiles 3 graph operations (input, operation, output) into 1 operation\n",
    "\n",
    "Removes need for Tensorflow Runtime (20 MB is significant on tiny devices)\n",
    "\n",
    "Allows new backends for hardware-specific optimizations (better portability)\n",
    "\n",
    "### [tfcompile](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/aot)\n",
    "Convert Graph into executable code\n",
    "\n",
    "### Compress/Distill Ensemble Models\n",
    "Convert ensembles or other complex models into smaller models\n",
    "\n",
    "Re-score training data with output of model being distilled \n",
    "\n",
    "Train smaller model to produce same output\n",
    "\n",
    "Output of smaller model learns more information than original label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimizing Serving Runtime Environment\n",
    "### Throughput\n",
    "**Option 1**:  Add more Tensorflow Serving servers behind **load balancer**\n",
    "\n",
    "**Option 2**:  Enable **request batching** in each Tensorflow Serving\n",
    "\n",
    "**Option Trade-offs**:  Higher Latency (bad) for Higher Throughput (good)\n",
    "\n",
    "```\n",
    "$TENSORFLOW_SERVING_HOME/bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \n",
    "--port=9000 \n",
    "--model_name=tensorflow_minimal \n",
    "--model_base_path=/root/models/tensorflow_minimal/export\n",
    "--enable_batching=true\n",
    "--max_batch_size=1000000\n",
    "--batch_timeout_micros=10000\n",
    "--max_enqueued_batches=1000000\n",
    "```\n",
    "![Request Batching](https://s3.amazonaws.com/fluxcapacitor.com/img/matrix-multiply-request-batching-handwritten.png)\n",
    "\n",
    "### Latency\n",
    "The deeper the model, the longer the latency\n",
    "\n",
    "Start inference in parallel where possible (ie. user inference in parallel with item inference)\n",
    "\n",
    "Pre-load common inputs from database (ie. user attributes, item attributes) \n",
    "\n",
    "Pre-compute/partial-compute common inputs (ie. popular word embeddings)\n",
    "\n",
    "### Memory\n",
    "Word embeddings are **huge**!\n",
    "\n",
    "Use **hashId** for each word\n",
    "\n",
    "Off-load embedding matrices to **parameter server** and share between serving servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Demos!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Deploy Tensorflow AI Model (Simple Model, Immutable Deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Tensorflow AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make things wide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def=None, width=1200, height=800, max_const_size=32, ungroup_gradients=False):\n",
    "    if not graph_def:\n",
    "        graph_def = tf.get_default_graph().as_graph_def()\n",
    "        \n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    data = str(strip_def)\n",
    "    if ungroup_gradients:\n",
    "        data = data.replace('\"gradients/', '\"b_')\n",
    "        #print(data)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(data), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:{}px;height:{}px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(width, height, code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If this errors out, increment the `export_version` variable, restart the Kernel, and re-run\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer(\"batch_size\", 10, \"The batch size to train\")\n",
    "flags.DEFINE_integer(\"epoch_number\", 10, \"Number of epochs to run trainer\")\n",
    "flags.DEFINE_integer(\"steps_to_validate\", 1,\n",
    "                     \"Steps to validate and print loss\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"./checkpoint/\",\n",
    "                    \"indicates the checkpoint directory\")\n",
    "#flags.DEFINE_string(\"model_path\", \"./model/\", \"The export path of the model\")\n",
    "flags.DEFINE_string(\"model_path\", \"/root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/\", \"The export path of the model\")\n",
    "flags.DEFINE_integer(\"export_version\", 27, \"The version number of the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-f107a23917ee>:25 in main.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "save/Const:0\n",
      "save/restore_all\n",
      "[0.027100563049316406] Epoch: 0\n",
      "[0.13298916816711426] Epoch: 1\n",
      "[0.13975763320922852] Epoch: 2\n",
      "[0.14050936698913574] Epoch: 3\n",
      "[0.1978766918182373] Epoch: 4\n",
      "[0.14339160919189453] Epoch: 5\n",
      "[0.14632725715637207] Epoch: 6\n",
      "[0.12981629371643066] Epoch: 7\n",
      "[0.14410161972045898] Epoch: 8\n",
      "[0.17600774765014648] Epoch: 9\n",
      "The model of w: 0.5030233263969421, b: 0.5030233263969421\n",
      "Exporting trained model to /root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Overwriting exports can cause corruption and are not allowed. Duplicate export dir: b'/root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f107a23917ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f107a23917ee>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m       })\n\u001b[1;32m     65\u001b[0m     \u001b[0mmodel_exporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done exporting!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exec_type, exec_value, exec_tb)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Session closing due to OpError: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexec_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     self._default_session_context_manager.__exit__(\n\u001b[0;32m-> 1207\u001b[0;31m         exec_type, exec_value, exec_tb)\n\u001b[0m\u001b[1;32m   1208\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   3515\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3516\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3517\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3519\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f107a23917ee>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredict_op\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       })\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmodel_exporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done exporting!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/contrib/session_bundle/exporter.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, export_dir_base, global_step_tensor, sess, exports_to_keep)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       raise RuntimeError(\"Overwriting exports can cause corruption and are \"\n\u001b[0;32m--> 264\u001b[0;31m                          \"not allowed. Duplicate export dir: %s\" % export_dir)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Output to a temporary directory which is atomically renamed to the final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overwriting exports can cause corruption and are not allowed. Duplicate export dir: b'/root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027'"
     ]
    }
   ],
   "source": [
    "# If this errors out, increment the `export_version` variable, restart the Kernel, and re-run\n",
    "\n",
    "def main():\n",
    "  # Define training data\n",
    "  x = np.ones(FLAGS.batch_size)\n",
    "  y = np.ones(FLAGS.batch_size)\n",
    "\n",
    "  # Define the model\n",
    "  X = tf.placeholder(tf.float32, shape=[None], name=\"X\")\n",
    "  Y = tf.placeholder(tf.float32, shape=[None], name=\"yhat\")\n",
    "  w = tf.Variable(1.0, name=\"weight\")\n",
    "  b = tf.Variable(1.0, name=\"bias\")\n",
    "  loss = tf.square(Y - tf.mul(X, w) - b)\n",
    "  train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "  predict_op  = tf.mul(X, w) + b\n",
    "\n",
    "  saver = tf.train.Saver()\n",
    "  checkpoint_dir = FLAGS.checkpoint_dir\n",
    "  checkpoint_file = checkpoint_dir + \"/checkpoint.ckpt\"\n",
    "  if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "  # Start the session\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      print(\"Continue training from the model {}\".format(ckpt.model_checkpoint_path))\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    saver_def = saver.as_saver_def()\n",
    "    print(saver_def.filename_tensor_name)\n",
    "    print(saver_def.restore_op_name)\n",
    "\n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    for epoch in range(FLAGS.epoch_number):\n",
    "      sess.run(train_op, feed_dict={X: x, Y: y})\n",
    "\n",
    "      # Start validating\n",
    "      if epoch % FLAGS.steps_to_validate == 0:\n",
    "        end_time = time.time()\n",
    "        print(\"[{}] Epoch: {}\".format(end_time - start_time, epoch))\n",
    "\n",
    "        saver.save(sess, checkpoint_file)\n",
    "        tf.train.write_graph(sess.graph_def, checkpoint_dir, 'trained_model.pb', as_text=False)\n",
    "        tf.train.write_graph(sess.graph_def, checkpoint_dir, 'trained_model.txt', as_text=True)\n",
    "\n",
    "        start_time = end_time\n",
    "\n",
    "    # Print model variables\n",
    "    w_value, b_value = sess.run([w, b])\n",
    "    print(\"The model of w: {}, b: {}\".format(w_value, b_value))\n",
    "\n",
    "    # Export the model\n",
    "    print(\"Exporting trained model to {}\".format(FLAGS.model_path))\n",
    "    model_exporter = exporter.Exporter(saver)\n",
    "    model_exporter.init(\n",
    "      sess.graph.as_graph_def(),\n",
    "      named_graph_signatures={\n",
    "        'inputs': exporter.generic_signature({\"features\": X}),\n",
    "        'outputs': exporter.generic_signature({\"prediction\": predict_op})\n",
    "      })\n",
    "    model_exporter.export(FLAGS.model_path, tf.constant(FLAGS.export_version), sess)\n",
    "    print('Done exporting!')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit and Deploy New Tensorflow AI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit Model to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 19 22:39 00000001\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 20:09 00000005\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:24 00000007\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:30 00000009\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:35 00000011\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:36 00000013\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 22:02 00000015\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 22:18 00000017\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 22 00:00 00000019\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 22 05:15 00000021\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 22 06:49 00000025\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 25 20:55 00000027\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "-rw-r--r-- 1 root root   241 Jan 25 20:55 checkpoint\r\n",
      "-rw-r--r-- 1 root root     8 Jan 25 20:55 export.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root   142 Jan 25 20:55 export.index\r\n",
      "-rw-r--r-- 1 root root 19394 Jan 25 20:55 export.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "\r\n",
      "Changes to be committed:\r\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\r\n",
      "\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/checkpoint\u001b[m\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.index\u001b[m\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.meta\u001b[m\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   SparkMLTensorflowAI-HybridCloud-ContinuousDeployment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../TensorFlow/DeepDream/deepdream.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Theano/Model Save and Load.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mSparkMLTensorflowAI-HybridCloud-ContinuousDeployment-Copy1.ipynb\u001b[m\r\n",
      "\t\u001b[31mcheckpoint/\u001b[m\r\n",
      "\t\u001b[31m../../../TimeSeries/Untitled.ipynb\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!git add --all /root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is ahead of 'origin/master' by 1 commit.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   SparkMLTensorflowAI-HybridCloud-ContinuousDeployment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Scikit-Learn/Scikit-Learn+Demos.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../TensorFlow/DeepDream/deepdream.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Theano/Model Save and Load.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mSparkMLTensorflowAI-HybridCloud-ContinuousDeployment-Azure.ipynb\u001b[m\r\n",
      "\t\u001b[31mcheckpoint/\u001b[m\r\n",
      "\t\u001b[31m../../../Spark/Pi/\u001b[m\r\n",
      "\t\u001b[31m../../../TimeSeries/Untitled.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 0ce7882] updated tensorflow model\r\n",
      " 4 files changed, 2 insertions(+)\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/checkpoint\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.data-00000-of-00001\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.index\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.meta\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"updated tensorflow model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "\r\n",
      "Changes to be committed:\r\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\r\n",
      "\r\n",
      "\t\u001b[32mmodified:   ../../../../scripts/pi.py\u001b[m\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   SparkMLTensorflowAI-HybridCloud-ContinuousDeployment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Scikit-Learn/Scikit-Learn+Demos.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../TensorFlow/DeepDream/deepdream.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Theano/Model Save and Load.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mSparkMLTensorflowAI-HybridCloud-ContinuousDeployment-Azure.ipynb\u001b[m\r\n",
      "\t\u001b[31mcheckpoint/\u001b[m\r\n",
      "\t\u001b[31m../../../Spark/Pi/\u001b[m\r\n",
      "\t\u001b[31m../../../TimeSeries/Untitled.ipynb\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: push.default is unset; its implicit value is changing in\n",
      "Git 2.0 from 'matching' to 'simple'. To squelch this message\n",
      "and maintain the current behavior after the default changes, use:\n",
      "\n",
      "  git config --global push.default matching\n",
      "\n",
      "To squelch this message and adopt the new behavior now, use:\n",
      "\n",
      "  git config --global push.default simple\n",
      "\n",
      "When push.default is set to 'matching', git will push local branches\n",
      "to the remote branches that already exist with the same name.\n",
      "\n",
      "In Git 2.0, Git will default to the more conservative 'simple'\n",
      "behavior, which only pushes the current branch to the corresponding\n",
      "remote branch that 'git pull' uses to update the current branch.\n",
      "\n",
      "See 'git help config' and search for 'push.default' for further information.\n",
      "(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode\n",
      "'current' instead of 'simple' if you sometimes use older versions of Git)\n",
      "\n",
      "Permission denied (publickey).\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n"
     ]
    }
   ],
   "source": [
    "# If this fails with \"Permission denied\", use terminal within jupyter to manually `git push`\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Airflow Workflow](http://demo.pipeline.io:8080/admin/) Deploys New Model through Github Post-Commit [Webhook](https://github.com/fluxcapacitor/pipeline/blob/master/scheduler.ml/airflow/github_webhook) to Triggers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=100% height=500px src=\"http://demo.pipeline.io:8080/admin\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=100% height=500px src=\"http://demo.pipeline.io:8080/admin\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Deploy Spark ML Model (Airbnb Model, Mutable Deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Out Spark Training Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes [CLI](https://github.com/fluxcapacitor/pipeline/wiki/Kubernetes-Commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replicationcontroller \"spark-worker-2-0-1\" scaled\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl scale --context=awsdemo --replicas=2 rc spark-worker-2-0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                           READY     STATUS    RESTARTS   AGE\r\n",
      "airflow-z2txg                                                  1/1       Running   0          51m\r\n",
      "hdfs-gd1pf                                                     1/1       Running   0          11d\r\n",
      "hystrix-rdx5g                                                  1/1       Running   0          9d\r\n",
      "jupyterhub-master-sqqjf                                        1/1       Running   0          11d\r\n",
      "metastore-1-2-1-jw8kx                                          1/1       Running   0          11d\r\n",
      "mysql-master-586zp                                             1/1       Running   0          11d\r\n",
      "prediction-codegen-b8c5b3016dc1eb4e655146be94cd2d56-p5m8f      1/1       Running   0          9d\r\n",
      "prediction-pmml-7db0fe5cbac0a14d38069985acd5b119-jv3ln         1/1       Running   0          9d\r\n",
      "prediction-tensorflow-60175981688eb64d9663a29c3ced8f45-4zndp   1/1       Running   0          9d\r\n",
      "spark-master-2-0-1-28vrg                                       1/1       Running   0          11d\r\n",
      "spark-worker-2-0-1-49qqg                                       1/1       Running   0          11d\r\n",
      "spark-worker-2-0-1-56hqq                                       1/1       Running   0          5d\r\n",
      "turbine-2gvb2                                                  1/1       Running   0          9d\r\n",
      "weavescope-app-c9khj                                           1/1       Running   0          11d\r\n",
      "weavescope-probe-0mtn7                                         1/1       Running   0          11d\r\n",
      "weavescope-probe-7qtz4                                         1/1       Running   0          11d\r\n",
      "weavescope-probe-kqt3z                                         1/1       Running   0          11d\r\n",
      "web-home-0c9jw                                                 1/1       Running   0          11d\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod --context=awsdemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weavescope Kubernetes [AWS Cluster](http://kubernetes-aws.demo.pipeline.io) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=100% height=500px src=\"http://kubernetes-aws.demo.pipeline.io\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=100% height=500px src=\"http://kubernetes-aws.demo.pipeline.io\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PMML from Spark ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 0**: Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=5731498, name='A 2-bdrm house in Plaka of Athens', space='Ideally located a unique house in a very peaceful neighborhood of Plaka, near Acropolis. It is a traditional house in the heart of the historical center of Athens, in Plaka. The kitchen is fully equipped with oven, fridge with freezer. Cutlery, dishes and pans, kettle, espresso coffee maker (espresso capsules are provided), toaster. There is also a vacuum cleaner and a laundry machine. One big closet will make your stay more comfortable. Bed linen, towels and bath amenities are provided. Moreover, the apartment is fully airconditioned. The apartment is very close to a greek traditional tavernas, a pharmacy, banks and public transport.  Airport or any other transport is available upon demand at an additional but very reasonable cost. ', price='120.0', bathrooms='1.0', bedrooms='2.0', room_type='Entire home/apt', square_feet=None, host_is_super_host='0.0', city='Athina', state=None, cancellation_policy='moderate', security_deposit='200.0', cleaning_fee='20.0', extra_people='15.0', minimum_nights='2', first_review='2015-04-07', instant_bookable='1.0', number_of_reviews='16', review_scores_rating='94.0', price_per_bedroom='60.0')\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"true\").option(\"header\", \"true\") \\\n",
    "  .load(\"s3a://datapalooza/airbnb/airbnb.csv.bz2\")\n",
    "\n",
    "df.registerTempTable(\"df\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198454\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Clean, Filter, and Summarize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_filtered = df.filter(\"price >= 50 AND price <= 750 AND bathrooms > 0.0 AND bedrooms is not null\")\n",
    "\n",
    "df_filtered.registerTempTable(\"df_filtered\")\n",
    "\n",
    "df_final = spark.sql(\"\"\"\n",
    "    select\n",
    "        id,\n",
    "        city,\n",
    "        case when state in('NY', 'CA', 'London', 'Berlin', 'TX' ,'IL', 'OR', 'DC', 'WA')\n",
    "            then state\n",
    "            else 'Other'\n",
    "        end as state,\n",
    "        space,\n",
    "        cast(price as double) as price,\n",
    "        cast(bathrooms as double) as bathrooms,\n",
    "        cast(bedrooms as double) as bedrooms,\n",
    "        room_type,\n",
    "        host_is_super_host,\n",
    "        cancellation_policy,\n",
    "        cast(case when security_deposit is null\n",
    "            then 0.0\n",
    "            else security_deposit\n",
    "        end as double) as security_deposit,\n",
    "        price_per_bedroom,\n",
    "        cast(case when number_of_reviews is null\n",
    "            then 0.0\n",
    "            else number_of_reviews\n",
    "        end as double) as number_of_reviews,\n",
    "        cast(case when extra_people is null\n",
    "            then 0.0\n",
    "            else extra_people\n",
    "        end as double) as extra_people,\n",
    "        instant_bookable,\n",
    "        cast(case when cleaning_fee is null\n",
    "            then 0.0\n",
    "            else cleaning_fee\n",
    "        end as double) as cleaning_fee,\n",
    "        cast(case when review_scores_rating is null\n",
    "            then 80.0\n",
    "            else review_scores_rating\n",
    "        end as double) as review_scores_rating,\n",
    "        cast(case when square_feet is not null and square_feet > 100\n",
    "            then square_feet\n",
    "            when (square_feet is null or square_feet <=100) and (bedrooms is null or bedrooms = 0)\n",
    "            then 350.0\n",
    "            else 380 * bedrooms\n",
    "        end as double) as square_feet\n",
    "    from df_filtered\n",
    "\"\"\").persist()\n",
    "\n",
    "df_final.registerTempTable(\"df_final\")\n",
    "\n",
    "df_final.select(\"square_feet\", \"price\", \"bedrooms\", \"bathrooms\", \"cleaning_fee\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_final.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_final.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most popular cities\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select \n",
    "        state,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by state\n",
    "    order by count(*) desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Most expensive popular cities\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select \n",
    "        city,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by city\n",
    "    order by avg(price) desc\n",
    "\"\"\").filter(\"ct > 25\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Define Continous and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = [\"bathrooms\", \\\n",
    "                       \"bedrooms\", \\\n",
    "                       \"security_deposit\", \\\n",
    "                       \"cleaning_fee\", \\\n",
    "                       \"extra_people\", \\\n",
    "                       \"number_of_reviews\", \\\n",
    "                       \"square_feet\", \\\n",
    "                       \"review_scores_rating\"]\n",
    "\n",
    "categorical_features = [\"room_type\", \\\n",
    "                        \"host_is_super_host\", \\\n",
    "                        \"cancellation_policy\", \\\n",
    "                        \"instant_bookable\", \\\n",
    "                        \"state\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Split Data into Training and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[training_dataset, validation_dataset] = df_final.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Continous Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "continuous_feature_assembler = VectorAssembler(inputCols=continuous_features, outputCol=\"unscaled_continuous_features\")\n",
    "\n",
    "continuous_feature_scaler = StandardScaler(inputCol=\"unscaled_continuous_features\", outputCol=\"scaled_continuous_features\", \\\n",
    "                                           withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: Categorical Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_feature_indexers = [StringIndexer(inputCol=x, \\\n",
    "                                              outputCol=\"{}_index\".format(x)) \\\n",
    "                                for x in categorical_features]\n",
    "\n",
    "categorical_feature_one_hot_encoders = [OneHotEncoder(inputCol=x.getOutputCol(), \\\n",
    "                                                      outputCol=\"oh_encoder_{}\".format(x.getOutputCol() )) \\\n",
    "                                        for x in categorical_feature_indexers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6**: Assemble our Features and Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols_lr = [x.getOutputCol() \\\n",
    "                   for x in categorical_feature_one_hot_encoders]\n",
    "feature_cols_lr.append(\"scaled_continuous_features\")\n",
    "\n",
    "feature_assembler_lr = VectorAssembler(inputCols=feature_cols_lr, \\\n",
    "                                       outputCol=\"features_lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7**: Train a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_4a97887ec5bffb967963\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression(featuresCol=\"features_lr\", \\\n",
    "                                     labelCol=\"price\", \\\n",
    "                                     predictionCol=\"price_prediction\", \\\n",
    "                                     maxIter=10, \\\n",
    "                                     regParam=0.3, \\\n",
    "                                     elasticNetParam=0.8)\n",
    "\n",
    "estimators_lr = \\\n",
    "  [continuous_feature_assembler, continuous_feature_scaler] \\\n",
    "  + categorical_feature_indexers + categorical_feature_one_hot_encoders \\\n",
    "  + [feature_assembler_lr] + [linear_regression]\n",
    "\n",
    "pipeline = Pipeline(stages=estimators_lr)\n",
    "\n",
    "pipeline_model = pipeline.fit(training_dataset)\n",
    "\n",
    "print(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8**:  Convert PipelineModel to PMML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n",
      "<PMML xmlns=\"http://www.dmg.org/PMML-4_3\" version=\"4.3\">\n",
      "\t<Header>\n",
      "\t\t<Application/>\n",
      "\t\t<Timestamp>2017-01-25T21:03:04Z</Timestamp>\n",
      "\t</Header>\n",
      "\t<DataDictionary>\n",
      "\t\t<DataField name=\"bathrooms\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"bedrooms\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"security_deposit\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"cleaning_fee\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"extra_people\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"number_of_reviews\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"square_feet\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"review_scores_rating\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"room_type\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"Entire home/apt\"/>\n",
      "\t\t\t<Value value=\"Private room\"/>\n",
      "\t\t\t<Value value=\"Shared room\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"host_is_super_host\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"0.0\"/>\n",
      "\t\t\t<Value value=\"1.0\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"cancellation_policy\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"strict\"/>\n",
      "\t\t\t<Value value=\"moderate\"/>\n",
      "\t\t\t<Value value=\"flexible\"/>\n",
      "\t\t\t<Value value=\"super_strict_30\"/>\n",
      "\t\t\t<Value value=\"no_refunds\"/>\n",
      "\t\t\t<Value value=\"super_strict_60\"/>\n",
      "\t\t\t<Value value=\"long_term\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"instant_bookable\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"0.0\"/>\n",
      "\t\t\t<Value value=\"1.0\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"state\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"Other\"/>\n",
      "\t\t\t<Value value=\"NY\"/>\n",
      "\t\t\t<Value value=\"CA\"/>\n",
      "\t\t\t<Value value=\"Berlin\"/>\n",
      "\t\t\t<Value value=\"IL\"/>\n",
      "\t\t\t<Value value=\"TX\"/>\n",
      "\t\t\t<Value value=\"WA\"/>\n",
      "\t\t\t<Value value=\"DC\"/>\n",
      "\t\t\t<Value value=\"OR\"/>\n",
      "\t\t\t<Value value=\"London\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"price\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t</DataDictionary>\n",
      "\t<TransformationDictionary>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[0]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"bathrooms\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">2.074530888987612</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[1]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"bedrooms\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">1.183342093127935</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[2]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"security_deposit\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.005515446077314265</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[3]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"cleaning_fee\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.02354892955874355</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[4]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"extra_people\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.05420544924382127</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[5]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"number_of_reviews\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.037137618066620755</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[6]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"square_feet\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.0027741086292747933</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[7]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"review_scores_rating\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.11353378155842442</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t</TransformationDictionary>\n",
      "\t<RegressionModel functionName=\"regression\">\n",
      "\t\t<MiningSchema>\n",
      "\t\t\t<MiningField name=\"price\" usageType=\"target\"/>\n",
      "\t\t\t<MiningField name=\"bathrooms\"/>\n",
      "\t\t\t<MiningField name=\"bedrooms\"/>\n",
      "\t\t\t<MiningField name=\"security_deposit\"/>\n",
      "\t\t\t<MiningField name=\"cleaning_fee\"/>\n",
      "\t\t\t<MiningField name=\"extra_people\"/>\n",
      "\t\t\t<MiningField name=\"number_of_reviews\"/>\n",
      "\t\t\t<MiningField name=\"square_feet\"/>\n",
      "\t\t\t<MiningField name=\"review_scores_rating\"/>\n",
      "\t\t\t<MiningField name=\"room_type\"/>\n",
      "\t\t\t<MiningField name=\"host_is_super_host\"/>\n",
      "\t\t\t<MiningField name=\"cancellation_policy\"/>\n",
      "\t\t\t<MiningField name=\"instant_bookable\"/>\n",
      "\t\t\t<MiningField name=\"state\"/>\n",
      "\t\t</MiningSchema>\n",
      "\t\t<RegressionTable intercept=\"-33.909482016407964\">\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[0]\" coefficient=\"16.846713112950372\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[1]\" coefficient=\"21.65744359456862\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[2]\" coefficient=\"1.019676161981778\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[3]\" coefficient=\"24.128563121458917\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[4]\" coefficient=\"2.2128469933598076\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[5]\" coefficient=\"-2.707908890362369\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[6]\" coefficient=\"3.296611618708919\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[7]\" coefficient=\"4.565176020759582\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Entire home/apt\" coefficient=\"26.3916496098938\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Private room\" coefficient=\"-12.814292762342133\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"host_is_super_host\" value=\"0.0\" coefficient=\"-5.230664391468683\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"strict\" coefficient=\"2.6265387778200915\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"moderate\" coefficient=\"-4.228524610632222\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"flexible\" coefficient=\"0.0\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"super_strict_30\" coefficient=\"66.09702679547543\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"no_refunds\" coefficient=\"0.0\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"super_strict_60\" coefficient=\"62.58306949412152\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"instant_bookable\" value=\"0.0\" coefficient=\"6.857977554604009\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Other\" coefficient=\"-10.872478259439536\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"NY\" coefficient=\"19.8002758153602\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"CA\" coefficient=\"12.244397012780297\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Berlin\" coefficient=\"-49.91171097312541\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"IL\" coefficient=\"16.65571231582757\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"TX\" coefficient=\"32.76371863225779\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"WA\" coefficient=\"-7.32245281839754\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"DC\" coefficient=\"5.449012606498783\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"OR\" coefficient=\"-16.720781290330176\"/>\n",
      "\t\t</RegressionTable>\n",
      "\t</RegressionModel>\n",
      "</PMML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jpmml import toPMMLBytes\n",
    "\n",
    "pmmlBytes = toPMMLBytes(spark, training_dataset, pipeline_model)\n",
    "\n",
    "print(pmmlBytes.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push PMML to Live, Running Spark ML Model Server (Mutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "update_url = 'http://prediction-pmml-aws.demo.pipeline.io/update-pmml/pmml_airbnb'\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'application/xml'\n",
    "\n",
    "req = urllib.request.Request(update_url, \\\n",
    "                             headers=update_headers, \\\n",
    "                             data=pmmlBytes)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.status) # Should return Http Status 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "update_url = 'http://prediction-pmml-gcp.demo.pipeline.io/update-pmml/pmml_airbnb'\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'application/xml'\n",
    "\n",
    "req = urllib.request.Request(update_url, \\\n",
    "                             headers=update_headers, \\\n",
    "                             data=pmmlBytes)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.status) # Should return Http Status 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"results\":[[{\\'price\\': \\'139.08123420618884\\'}]]'\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "evaluate_url = 'http://prediction-pmml-aws.demo.pipeline.io/evaluate-pmml/pmml_airbnb'\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "\n",
    "input_params = '{\"bathrooms\":2.0, \\\n",
    "                 \"bedrooms\":2.0, \\\n",
    "                 \"security_deposit\":175.00, \\\n",
    "                 \"cleaning_fee\":25.0, \\\n",
    "                 \"extra_people\":1.0, \\\n",
    "                 \"number_of_reviews\": 2.0, \\\n",
    "                 \"square_feet\": 250.0, \\\n",
    "                 \"review_scores_rating\": 2.0, \\\n",
    "                 \"room_type\": \"Entire home/apt\", \\\n",
    "                 \"host_is_super_host\": \"0.0\", \\\n",
    "                 \"cancellation_policy\": \"flexible\", \\\n",
    "                 \"instant_bookable\": \"1.0\", \\\n",
    "                 \"state\": \"CA\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = urllib.request.Request(evaluate_url, \\\n",
    "                             headers=evaluate_headers, \\\n",
    "                             data=encoded_input_params)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"results\":[[{\\'price\\': \\'139.08123420618884\\'}]]'\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "evaluate_url = 'http://prediction-pmml-aws.demo.pipeline.io/evaluate-pmml/pmml_airbnb'\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "\n",
    "input_params = '{\"bathrooms\":2.0, \\\n",
    "                 \"bedrooms\":2.0, \\\n",
    "                 \"security_deposit\":175.00, \\\n",
    "                 \"cleaning_fee\":25.0, \\\n",
    "                 \"extra_people\":1.0, \\\n",
    "                 \"number_of_reviews\": 2.0, \\\n",
    "                 \"square_feet\": 250.0, \\\n",
    "                 \"review_scores_rating\": 2.0, \\\n",
    "                 \"room_type\": \"Entire home/apt\", \\\n",
    "                 \"host_is_super_host\": \"0.0\", \\\n",
    "                 \"cancellation_policy\": \"flexible\", \\\n",
    "                 \"instant_bookable\": \"1.0\", \\\n",
    "                 \"state\": \"CA\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = urllib.request.Request(evaluate_url, \\\n",
    "                             headers=evaluate_headers, \\\n",
    "                             data=encoded_input_params)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "evaluate_url = 'http://prediction-pmml-gcp.demo.pipeline.io/evaluate-pmml/pmml_airbnb'\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "\n",
    "input_params = '{\"bathrooms\":2.0, \\\n",
    "                 \"bedrooms\":2.0, \\\n",
    "                 \"security_deposit\":175.00, \\\n",
    "                 \"cleaning_fee\":25.0, \\\n",
    "                 \"extra_people\":1.0, \\\n",
    "                 \"number_of_reviews\": 2.0, \\\n",
    "                 \"square_feet\": 250.0, \\\n",
    "                 \"review_scores_rating\": 2.0, \\\n",
    "                 \"room_type\": \"Entire home/apt\", \\\n",
    "                 \"host_is_super_host\": \"0.0\", \\\n",
    "                 \"cancellation_policy\": \"flexible\", \\\n",
    "                 \"instant_bookable\": \"1.0\", \\\n",
    "                 \"state\": \"CA\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = urllib.request.Request(evaluate_url, \\\n",
    "                             headers=evaluate_headers, \\\n",
    "                             data=encoded_input_params)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Java-based Model (Simple Model, Mutable Deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "sourceBytes = '                                                      \\n\\\n",
    "  private String str;                                                \\n\\\n",
    "                                                                     \\n\\\n",
    "  public void initialize(Map<String, Object> args) {                 \\n\\\n",
    "  }                                                                  \\n\\\n",
    "                                                                     \\n\\\n",
    "  public Object predict(Map<String, Object> inputs) {                \\n\\\n",
    "      String id = (String)inputs.get(\"id\");                          \\n\\\n",
    "                                                                     \\n\\\n",
    "      return id.equals(\"21619\");                                     \\n\\\n",
    "  }                                                                  \\n\\\n",
    "'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* 001 */\n",
      "/* 002 */ private String str;\n",
      "/* 003 */\n",
      "/* 004 */ public void initialize(Map<String, Object> args) {\n",
      "/* 005 */ }\n",
      "/* 006 */\n",
      "/* 007 */ public Object predict(Map<String, Object> inputs) {\n",
      "/* 008 */   String id = (String)inputs.get(\"id\");\n",
      "/* 009 */\n",
      "/* 010 */   return id.equals(\"21619\");\n",
      "/* 011 */ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_equals'\n",
    "update_url = 'http://prediction-codegen-aws.demo.pipeline.io/update-codegen/%s/' % name\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* 001 */\n",
      "/* 002 */ private String str;\n",
      "/* 003 */\n",
      "/* 004 */ public void initialize(Map<String, Object> args) {\n",
      "/* 005 */ }\n",
      "/* 006 */\n",
      "/* 007 */ public Object predict(Map<String, Object> inputs) {\n",
      "/* 008 */   String id = (String)inputs.get(\"id\");\n",
      "/* 009 */\n",
      "/* 010 */   return id.equals(\"21619\");\n",
      "/* 011 */ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_equals'\n",
    "update_url = 'http://prediction-codegen-gcp.demo.pipeline.io/update-codegen/%s/' % name\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'false'\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_equals'\n",
    "evaluate_url = 'http://prediction-codegen-aws.demo.pipeline.io/evaluate-codegen/%s' % name\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"id\":\"21618\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'true'\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_equals'\n",
    "evaluate_url = 'http://prediction-codegen-aws.demo.pipeline.io/evaluate-codegen/%s' % name\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"id\":\"21619\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Java Model (HttpClient Model, Mutable Deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "sourceBytes = '                                                         \\n\\\n",
    "  public Map<String, Object> data = new HashMap<String, Object>();      \\n\\\n",
    "                                                                        \\n\\\n",
    "  public void initialize(Map<String, Object> args) {                    \\n\\\n",
    "    data.put(\"url\", \"http://demo.pipeline.io:9040/prediction/\");        \\n\\\n",
    "  }                                                                     \\n\\\n",
    "                                                                        \\n\\\n",
    "  public Object predict(Map<String, Object> inputs) {                   \\n\\\n",
    "    try {                                                               \\n\\\n",
    "      String userId = (String)inputs.get(\"userId\");                     \\n\\\n",
    "      String itemId = (String)inputs.get(\"itemId\");                     \\n\\\n",
    "      String url = data.get(\"url\") + \"/\" + userId + \"/\" + itemId;       \\n\\\n",
    "                                                                        \\n\\\n",
    "      return org.apache.http.client.fluent.Request                      \\n\\\n",
    "        .Get(url)                                                       \\n\\\n",
    "        .execute()                                                      \\n\\\n",
    "        .returnContent();                                               \\n\\\n",
    "                                                                        \\n\\\n",
    "    } catch(Exception exc) {                                            \\n\\\n",
    "      System.out.println(exc);                                          \\n\\\n",
    "      throw exc;                                                        \\n\\\n",
    "    }                                                                   \\n\\\n",
    "  }                                                                     \\n\\\n",
    "'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* 001 */\n",
      "/* 002 */ public Map<String, Object> data = new HashMap<String, Object>();\n",
      "/* 003 */\n",
      "/* 004 */ public void initialize(Map<String, Object> args) {\n",
      "/* 005 */   data.put(\"url\", \"http://demo.pipeline.io:9040/prediction/\");\n",
      "/* 006 */ }\n",
      "/* 007 */\n",
      "/* 008 */ public Object predict(Map<String, Object> inputs) {\n",
      "/* 009 */   try {\n",
      "/* 010 */     String userId = (String)inputs.get(\"userId\");\n",
      "/* 011 */     String itemId = (String)inputs.get(\"itemId\");\n",
      "/* 012 */     String url = data.get(\"url\") + \"/\" + userId + \"/\" + itemId;\n",
      "/* 013 */\n",
      "/* 014 */     return org.apache.http.client.fluent.Request\n",
      "/* 015 */     .Get(url)\n",
      "/* 016 */     .execute()\n",
      "/* 017 */     .returnContent();\n",
      "/* 018 */\n",
      "/* 019 */   } catch(Exception exc) {\n",
      "/* 020 */     System.out.println(exc);\n",
      "/* 021 */     throw exc;\n",
      "/* 022 */   }\n",
      "/* 023 */ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "# Note:  Must have trailing '/'\n",
    "update_url = 'http://prediction-codegen-aws.demo.pipeline.io/update-codegen/%s/' % name\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "# Note:  Must have trailing '/'\n",
    "update_url = 'http://prediction-codegen-gcp.demo.pipeline.io/update-codegen/%s/' % name\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "evaluate_url = 'http://prediction-codegen-aws.demo.pipeline.io/evaluate-codegen/%s' % name\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"userId\":\"21619\", \"itemId\":\"10006\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "evaluate_url = 'http://prediction-codegen-gcp.demo.pipeline.io/evaluate-codegen/%s' % name\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"userId\":\"21619\", \"itemId\":\"10006\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test and Compare Cloud Providers (AWS and Google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Performance Across Cloud Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetflixOSS Services [Dashboard](http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D) (Hystrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=100% height=500px src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=100% height=500px src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Load Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run JMeter Tests from Local Laptop (Limited by Laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Headless JMeter Tests from Training Clusters in Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spark ML - PMML - Airbnb\n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-airbnb-rc.yaml\n",
    "!kubectl create --context=gcpdemo -f /root/pipeline/loadtest.ml/loadtest-aws-airbnb-rc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Codegen - Java - Simple\n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-equals-rc.yaml\n",
    "!kubectl create --context=gcpdemo -f /root/pipeline/loadtest.ml/loadtest-aws-equals-rc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tensorflow AI - Tensorflow Serving - Simple \n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-minimal-rc.yaml\n",
    "!kubectl create --context=gcpdemo -f /root/pipeline/loadtest.ml/loadtest-aws-minimal-rc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Load Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kubectl delete --context=awsdemo rc loadtest-aws-airbnb\n",
    "!kubectl delete --context=gcpdemo rc loadtest-aws-airbnb\n",
    "!kubectl delete --context=awsdemo rc loadtest-aws-equals\n",
    "!kubectl delete --context=gcpdemo rc loadtest-aws-equals\n",
    "!kubectl delete --context=awsdemo rc loadtest-aws-minimal\n",
    "!kubectl delete --context=gcpdemo rc loadtest-aws-minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Deploy Tensorflow AI (Simple Model, Immutable Deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes [CLI](https://github.com/fluxcapacitor/pipeline/wiki/Kubernetes-Commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!kubectl rolling-update prediction-tensorflow --context=awsdemo --image-pull-policy=Always --image=fluxcapacitor/prediction-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl get pod --context=awsdemo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rolling-update prediction-tensorflow --context=gcpdemo --image-pull-policy=Always --image=fluxcapacitor/prediction-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl get pod --context=gcpdemo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Q&A"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nbpresent": {
   "slides": {
    "0e6bc8b6-3cc5-496c-a34b-11d192afa91e": {
     "id": "0e6bc8b6-3cc5-496c-a34b-11d192afa91e",
     "prev": "aca594eb-585a-4405-b367-08bbe36b7e46",
     "regions": {
      "42084308-8543-4a24-918b-e452e3cba2e8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4d6901a2-06fc-4cc2-9168-0b4dd20436c3",
        "part": "whole"
       },
       "id": "42084308-8543-4a24-918b-e452e3cba2e8"
      }
     }
    },
    "10e8bf08-9a8f-4615-824e-4c015cb48051": {
     "id": "10e8bf08-9a8f-4615-824e-4c015cb48051",
     "prev": "6495f7a9-692a-452e-8a08-d34afb46a92a",
     "regions": {
      "f8860415-d84f-453f-b095-5a68337325ac": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de258cfb-7c21-40cf-b3ee-04228689eab0",
        "part": "whole"
       },
       "id": "f8860415-d84f-453f-b095-5a68337325ac"
      }
     }
    },
    "1ce58837-1471-4d9e-90bd-56c2482444bf": {
     "id": "1ce58837-1471-4d9e-90bd-56c2482444bf",
     "prev": "c121e0e8-a5cb-4e28-a578-f4246b9bc82e",
     "regions": {
      "53848919-ae68-4e10-b72b-40191b3af7bb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "023050ea-c894-4ffe-869f-2f27f03e524a",
        "part": "whole"
       },
       "id": "53848919-ae68-4e10-b72b-40191b3af7bb"
      }
     }
    },
    "32b2322c-9925-4e38-a692-05f3544576c3": {
     "id": "32b2322c-9925-4e38-a692-05f3544576c3",
     "prev": "10e8bf08-9a8f-4615-824e-4c015cb48051",
     "regions": {
      "251138f3-82aa-49e6-8e01-621ca02eb8fe": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b08fcd17-3ecd-4e73-a494-570728a3e129",
        "part": "whole"
       },
       "id": "251138f3-82aa-49e6-8e01-621ca02eb8fe"
      }
     }
    },
    "5e9dc412-fd7e-4a17-a5bd-1ac44cc9cdc6": {
     "id": "5e9dc412-fd7e-4a17-a5bd-1ac44cc9cdc6",
     "prev": "ae6895f7-9ad3-4ac7-a3a7-b23dddc95276",
     "regions": {
      "8a35ac4a-1620-48f4-90ec-3a9c5c577271": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "34e2d7fe-478c-4f42-aab6-0e17e4424576",
        "part": "whole"
       },
       "id": "8a35ac4a-1620-48f4-90ec-3a9c5c577271"
      }
     }
    },
    "6495f7a9-692a-452e-8a08-d34afb46a92a": {
     "id": "6495f7a9-692a-452e-8a08-d34afb46a92a",
     "prev": "5e9dc412-fd7e-4a17-a5bd-1ac44cc9cdc6",
     "regions": {
      "8c118309-a5f7-4970-8997-fa6d31be0cf9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a0dd485d-6cdf-4ccc-ba0c-60b2ed06bac7",
        "part": "whole"
       },
       "id": "8c118309-a5f7-4970-8997-fa6d31be0cf9"
      }
     }
    },
    "6a260c4b-6faa-456e-9680-dd7cbebe0933": {
     "id": "6a260c4b-6faa-456e-9680-dd7cbebe0933",
     "prev": "32b2322c-9925-4e38-a692-05f3544576c3",
     "regions": {
      "f65b7ebd-c02e-4088-95dc-8c90a5dffd09": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f5525416-d535-4377-bdf8-b91463fce353",
        "part": "whole"
       },
       "id": "f65b7ebd-c02e-4088-95dc-8c90a5dffd09"
      }
     }
    },
    "9c2c1cd9-1811-417c-8a27-edfef797f18b": {
     "id": "9c2c1cd9-1811-417c-8a27-edfef797f18b",
     "prev": "ee9cdb3f-6fb6-4497-ba5d-0fcddf43b8fd",
     "regions": {
      "867affd3-66d0-4835-bf85-a7b0e596d78e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ca731c95-6e39-4db8-a51c-f467a315616d",
        "part": "whole"
       },
       "id": "867affd3-66d0-4835-bf85-a7b0e596d78e"
      }
     }
    },
    "aca594eb-585a-4405-b367-08bbe36b7e46": {
     "id": "aca594eb-585a-4405-b367-08bbe36b7e46",
     "prev": "9c2c1cd9-1811-417c-8a27-edfef797f18b",
     "regions": {
      "22168c7b-acfd-4487-b57e-97aa88e5f3e8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ca8cd2ab-3693-4b40-90c0-d4b6adf8c20e",
        "part": "whole"
       },
       "id": "22168c7b-acfd-4487-b57e-97aa88e5f3e8"
      }
     }
    },
    "ae6895f7-9ad3-4ac7-a3a7-b23dddc95276": {
     "id": "ae6895f7-9ad3-4ac7-a3a7-b23dddc95276",
     "prev": "0e6bc8b6-3cc5-496c-a34b-11d192afa91e",
     "regions": {
      "1bf1c48a-1011-4992-8eaf-ef8e89a3d9c9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bd5629b7-e48e-42b7-ae26-38ed501f0246",
        "part": "whole"
       },
       "id": "1bf1c48a-1011-4992-8eaf-ef8e89a3d9c9"
      }
     },
     "theme": null
    },
    "c121e0e8-a5cb-4e28-a578-f4246b9bc82e": {
     "id": "c121e0e8-a5cb-4e28-a578-f4246b9bc82e",
     "prev": null,
     "regions": {
      "bf22675f-7d52-4ded-b588-7ddc477b17d6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fcb54439-1c2c-46ce-9d92-e77df43393db",
        "part": "whole"
       },
       "id": "bf22675f-7d52-4ded-b588-7ddc477b17d6"
      }
     }
    },
    "ee9cdb3f-6fb6-4497-ba5d-0fcddf43b8fd": {
     "id": "ee9cdb3f-6fb6-4497-ba5d-0fcddf43b8fd",
     "prev": "ff384e75-fefa-4966-a506-a12d5c4c770f",
     "regions": {
      "8d7dad4a-1d39-4ea7-8e9d-938bb9e7c00f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e4189884-f8d1-4d9a-827d-5ffe9bf7b21b",
        "part": "whole"
       },
       "id": "8d7dad4a-1d39-4ea7-8e9d-938bb9e7c00f"
      }
     }
    },
    "ff384e75-fefa-4966-a506-a12d5c4c770f": {
     "id": "ff384e75-fefa-4966-a506-a12d5c4c770f",
     "prev": "1ce58837-1471-4d9e-90bd-56c2482444bf",
     "regions": {
      "dd92502b-768b-431a-a5c3-6601da433340": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5dc02aa0-da66-4cce-b6f0-4e2253f8743c",
        "part": "whole"
       },
       "id": "dd92502b-768b-431a-a5c3-6601da433340"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
