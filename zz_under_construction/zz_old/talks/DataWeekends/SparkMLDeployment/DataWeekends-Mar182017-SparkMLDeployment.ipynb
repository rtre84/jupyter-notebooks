{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Am I?\n",
    "## Chris Fregly\n",
    "\n",
    "![Chris Fregly](https://s3.amazonaws.com/fluxcapacitor.com/img/fregly-300x300.png)\n",
    "\n",
    "![Chris Fregly Emoji](https://s3.amazonaws.com/fluxcapacitor.com/img/fregly-emoji-300x300.png)\n",
    "## Research Scientist, Founder @ **[PipelineIO](http://pipeline.io)** \n",
    "\n",
    "![PipelineIO](http://pipeline.io/images/pipeline-io-logo-shadow-210x186.png)\n",
    "\n",
    "## Video Series Author \"High Performance Tensorflow in Production\" @ [OReilly](http://oreilly.com) (Coming Soon)\n",
    "\n",
    "![OReilly Media](https://s3.amazonaws.com/fluxcapacitor.com/img/oreilly-logo.png)\n",
    "\n",
    "## Founder @ **[Advanced Spark and Tensorflow Meetup](http://http://www.meetup.com/Advanced-Spark-and-TensorFlow-Meetup/)**\n",
    "\n",
    "![Advanced Spark and Tensorflow Meetup](https://s3.amazonaws.com/fluxcapacitor.com/img/advanced-spark-tensorflow-meetup-logo-green.png)\n",
    "\n",
    "## **[Github Repo](https://github.com/fluxcapacitor/pipeline)**\n",
    "\t\n",
    "![Github Repo](https://s3.amazonaws.com/fluxcapacitor.com/img/pipeline-io-github-1000-stars.png)\n",
    "\n",
    "## **[DockerHub Repo](https://hub.docker.com/u/fluxcapacitor/)**\n",
    "\n",
    "![DockerHub](https://s3.amazonaws.com/fluxcapacitor.com/img/dockerhub-logo.png)\n",
    "\n",
    "## **[Slideshare](http://www.slideshare.net/cfregly)**\n",
    "\n",
    "![Slideshare](http://advancedspark.com/img/slideshare.png)\n",
    "\n",
    "## **[YouTube](https://www.youtube.com/playlist?list=PL7pBcJ870QHeNRBXdKirc4fdtbtbB5Xy-)**\n",
    "\n",
    "![YouTube](http://advancedspark.com/img/youtube-300x134.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Was I?\n",
    "## Software Engineer @ **Netflix**, **Databricks**, **IBM Spark Tech Center**\n",
    "\n",
    "![Netflix](http://pipeline.io/images/netflixoss-logo-white-295x55.png) \n",
    "\n",
    "![Databricks](http://pipeline.io/images/databricks-logo-350x69.png) \n",
    "\n",
    "![IBM Spark Tech Center](https://s3.amazonaws.com/fluxcapacitor.com/img/ibm-spark-logo-197x148.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Model Deployments\n",
    "## KeyValue\n",
    "ie. Recommendations\n",
    "\n",
    "In-memory: Redis, Memcache\n",
    "\n",
    "On-disk:  Cassandra, RocksDB\n",
    "\n",
    "First-class Servable in [Tensorflow Serving](https://github.com/tensorflow/serving/tree/master/tensorflow_serving/servables)\n",
    "\n",
    "## PMML\n",
    "It's Useful and [Well-Supported](https://github.com/jpmml)\n",
    "\n",
    "Apple, Cisco, [Airbnb](http://nerds.airbnb.com/architecting-machine-learning-system-risk/), HomeAway, etc\n",
    "\n",
    "Please Don't Re-build It - Reduce Your Technical Debt!\n",
    "\n",
    "![Regression Model PMML](https://s3.amazonaws.com/fluxcapacitor.com/img/regression-model-pmml2.png)\n",
    "\n",
    "## Native Code Generation (CPU and GPU)\n",
    "Hand-coded (Python + Pickling)\n",
    "\n",
    "Generate Java Code from PMML?\n",
    "\n",
    "![Regression Model Java Codegen](https://s3.amazonaws.com/fluxcapacitor.com/img/regression-model-codegen2.png)\n",
    "\n",
    "## Tensorflow Models\n",
    "[freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py): Combine Tensorflow Graph (Static) with Trained Weights (Checkpoints) into Single Deployable Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--master spark://spark-master-2-1-0:7077 --conf spark.cores.max=1 --conf spark.executor.memory=512m --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1 --jars /root/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar --py-files /root/lib/jpmml.py pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "# You may need to Reconnect (more than Restart) the Kernel to pick up changes to these sett\n",
    "import os\n",
    "\n",
    "master = '--master spark://spark-master-2-1-0:7077'\n",
    "conf = '--conf spark.cores.max=1 --conf spark.executor.memory=512m'\n",
    "packages = '--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1'\n",
    "jars = '--jars /root/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar'\n",
    "py_files = '--py-files /root/lib/jpmml.py'\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = master \\\n",
    "  + ' ' + conf \\\n",
    "  + ' ' + packages \\\n",
    "  + ' ' + jars \\\n",
    "  + ' ' + py_files \\\n",
    "  + ' ' + 'pyspark-shell'\n",
    "\n",
    "print(os.environ['PYSPARK_SUBMIT_ARGS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Spark ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 0**: Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=5731498, name='A 2-bdrm house in Plaka of Athens', space='Ideally located a unique house in a very peaceful neighborhood of Plaka, near Acropolis. It is a traditional house in the heart of the historical center of Athens, in Plaka. The kitchen is fully equipped with oven, fridge with freezer. Cutlery, dishes and pans, kettle, espresso coffee maker (espresso capsules are provided), toaster. There is also a vacuum cleaner and a laundry machine. One big closet will make your stay more comfortable. Bed linen, towels and bath amenities are provided. Moreover, the apartment is fully airconditioned. The apartment is very close to a greek traditional tavernas, a pharmacy, banks and public transport.  Airport or any other transport is available upon demand at an additional but very reasonable cost. ', price='120.0', bathrooms='1.0', bedrooms='2.0', room_type='Entire home/apt', square_feet=None, host_is_super_host='0.0', city='Athina', state=None, cancellation_policy='moderate', security_deposit='200.0', cleaning_fee='20.0', extra_people='15.0', minimum_nights='2', first_review='2015-04-07', instant_bookable='1.0', number_of_reviews='16', review_scores_rating='94.0', price_per_bedroom='60.0')\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"true\").option(\"header\", \"true\") \\\n",
    "  .load(\"s3a://datapalooza/airbnb/airbnb.csv.bz2\")\n",
    "\n",
    "df.registerTempTable(\"df\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198576\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1**: Clean, Filter, and Summarize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|summary|      square_feet|             price|          bedrooms|         bathrooms|      cleaning_fee|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|  count|           151864|            151864|            151864|            151864|            151864|\n",
      "|   mean|545.5920823895063|131.00769109202972|1.3336998893747036|1.1988786019069695| 37.25118527103198|\n",
      "| stddev| 363.234618108484| 89.59372969879456|0.8460907193971745|0.4836515839573292|42.625502170779164|\n",
      "|    min|            104.0|              50.0|               0.0|               0.5|               0.0|\n",
      "|    max|          32292.0|             750.0|              10.0|               8.0|             700.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(\"price >= 50 AND price <= 750 AND bathrooms > 0.0 AND bedrooms is not null\")\n",
    "\n",
    "df_filtered.registerTempTable(\"df_filtered\")\n",
    "\n",
    "df_final = spark.sql(\"\"\"\n",
    "    select\n",
    "        id,\n",
    "        city,\n",
    "        case when state in('NY', 'CA', 'London', 'Berlin', 'TX' ,'IL', 'OR', 'DC', 'WA')\n",
    "            then state\n",
    "            else 'Other'\n",
    "        end as state,\n",
    "        space,\n",
    "        cast(price as double) as price,\n",
    "        cast(bathrooms as double) as bathrooms,\n",
    "        cast(bedrooms as double) as bedrooms,\n",
    "        room_type,\n",
    "        host_is_super_host,\n",
    "        cancellation_policy,\n",
    "        cast(case when security_deposit is null\n",
    "            then 0.0\n",
    "            else security_deposit\n",
    "        end as double) as security_deposit,\n",
    "        price_per_bedroom,\n",
    "        cast(case when number_of_reviews is null\n",
    "            then 0.0\n",
    "            else number_of_reviews\n",
    "        end as double) as number_of_reviews,\n",
    "        cast(case when extra_people is null\n",
    "            then 0.0\n",
    "            else extra_people\n",
    "        end as double) as extra_people,\n",
    "        instant_bookable,\n",
    "        cast(case when cleaning_fee is null\n",
    "            then 0.0\n",
    "            else cleaning_fee\n",
    "        end as double) as cleaning_fee,\n",
    "        cast(case when review_scores_rating is null\n",
    "            then 80.0\n",
    "            else review_scores_rating\n",
    "        end as double) as review_scores_rating,\n",
    "        cast(case when square_feet is not null and square_feet > 100\n",
    "            then square_feet\n",
    "            when (square_feet is null or square_feet <=100) and (bedrooms is null or bedrooms = 0)\n",
    "            then 350.0\n",
    "            else 380 * bedrooms\n",
    "        end as double) as square_feet\n",
    "    from df_filtered\n",
    "\"\"\").persist()\n",
    "\n",
    "df_final.registerTempTable(\"df_final\")\n",
    "\n",
    "df_final.select(\"square_feet\", \"price\", \"bedrooms\", \"bathrooms\", \"cleaning_fee\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151864\n"
     ]
    }
   ],
   "source": [
    "print(df_final.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(id,IntegerType,true),StructField(city,StringType,true),StructField(state,StringType,true),StructField(space,StringType,true),StructField(price,DoubleType,true),StructField(bathrooms,DoubleType,true),StructField(bedrooms,DoubleType,true),StructField(room_type,StringType,true),StructField(host_is_super_host,StringType,true),StructField(cancellation_policy,StringType,true),StructField(security_deposit,DoubleType,true),StructField(price_per_bedroom,StringType,true),StructField(number_of_reviews,DoubleType,true),StructField(extra_people,DoubleType,true),StructField(instant_bookable,StringType,true),StructField(cleaning_fee,DoubleType,true),StructField(review_scores_rating,DoubleType,true),StructField(square_feet,DoubleType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(df_final.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+---------+\n",
      "| state|   ct|         avg_price|max_price|\n",
      "+------+-----+------------------+---------+\n",
      "| Other|87467|122.00503046863389|    750.0|\n",
      "|    NY|22899| 145.9446264028997|    750.0|\n",
      "|    CA|20750|157.40173493975902|    750.0|\n",
      "|Berlin| 6034|  80.6433543254889|    650.0|\n",
      "|    IL| 3552|141.46903153153153|    690.0|\n",
      "|    TX| 3108|195.25611325611325|    750.0|\n",
      "|    WA| 2700| 131.4962962962963|    750.0|\n",
      "|    DC| 2590|136.64015444015445|    720.0|\n",
      "|    OR| 1954|114.02661207778915|    700.0|\n",
      "|London|  810|108.84444444444445|    600.0|\n",
      "+------+-----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most popular cities\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select \n",
    "        state,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by state\n",
    "    order by count(*) desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------------+---------+\n",
      "|               city| ct|         avg_price|max_price|\n",
      "+-------------------+---+------------------+---------+\n",
      "|         Palm Beach| 26| 348.7692307692308|    701.0|\n",
      "|        Watsonville| 38| 313.3157894736842|    670.0|\n",
      "|             Malibu|136| 280.9852941176471|    750.0|\n",
      "|             Avalon| 38|262.42105263157896|    701.0|\n",
      "|           Capitola| 35|             246.4|    650.0|\n",
      "|           Tamarama| 72|             238.5|    750.0|\n",
      "|    Manhattan Beach|109|232.10091743119267|    700.0|\n",
      "|Rancho Palos Verdes| 39|230.02564102564102|    750.0|\n",
      "|       Avalon Beach| 38|229.60526315789474|    620.0|\n",
      "|            Newport| 52| 223.8653846153846|    750.0|\n",
      "|      Darling Point| 29|221.51724137931035|    623.0|\n",
      "|        Middle Park| 34| 212.7941176470588|    671.0|\n",
      "|            Balmain| 55|212.56363636363636|    712.0|\n",
      "|        North Bondi|180|206.68333333333334|    750.0|\n",
      "|             Bronte|144|203.70833333333334|    750.0|\n",
      "|        Queenscliff| 40|           201.925|    650.0|\n",
      "|          Lilyfield| 26|198.92307692307693|    701.0|\n",
      "|         Freshwater| 54| 198.5185185185185|    650.0|\n",
      "|           La Jolla| 52|197.82692307692307|    649.0|\n",
      "|     Marina del Rey|205| 196.6390243902439|    550.0|\n",
      "+-------------------+---+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most expensive popular cities\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select \n",
    "        city,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by city\n",
    "    order by avg(price) desc\n",
    "\"\"\").filter(\"ct > 25\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2**: Define Continous and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = [\"bathrooms\", \\\n",
    "                       \"bedrooms\", \\\n",
    "                       \"security_deposit\", \\\n",
    "                       \"cleaning_fee\", \\\n",
    "                       \"extra_people\", \\\n",
    "                       \"number_of_reviews\", \\\n",
    "                       \"square_feet\", \\\n",
    "                       \"review_scores_rating\"]\n",
    "\n",
    "categorical_features = [\"room_type\", \\\n",
    "                        \"host_is_super_host\", \\\n",
    "                        \"cancellation_policy\", \\\n",
    "                        \"instant_bookable\", \\\n",
    "                        \"state\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3**: Split Data into Training and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[training_dataset, validation_dataset] = df_final.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4**: Continous Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_feature_assembler = VectorAssembler(inputCols=continuous_features, outputCol=\"unscaled_continuous_features\")\n",
    "\n",
    "continuous_feature_scaler = StandardScaler(inputCol=\"unscaled_continuous_features\", outputCol=\"scaled_continuous_features\", \\\n",
    "                                           withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5**: Categorical Feature Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_feature_indexers = [StringIndexer(inputCol=x, \\\n",
    "                                              outputCol=\"{}_index\".format(x)) \\\n",
    "                                for x in categorical_features]\n",
    "\n",
    "categorical_feature_one_hot_encoders = [OneHotEncoder(inputCol=x.getOutputCol(), \\\n",
    "                                                      outputCol=\"oh_encoder_{}\".format(x.getOutputCol() )) \\\n",
    "                                        for x in categorical_feature_indexers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6**: Assemble our Features and Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols_lr = [x.getOutputCol() \\\n",
    "                   for x in categorical_feature_one_hot_encoders]\n",
    "feature_cols_lr.append(\"scaled_continuous_features\")\n",
    "\n",
    "feature_assembler_lr = VectorAssembler(inputCols=feature_cols_lr, \\\n",
    "                                       outputCol=\"features_lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 7**: Train a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_4a17a6ecb15ee91807b3\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression(featuresCol=\"features_lr\", \\\n",
    "                                     labelCol=\"price\", \\\n",
    "                                     predictionCol=\"price_prediction\", \\\n",
    "                                     maxIter=10, \\\n",
    "                                     regParam=0.3, \\\n",
    "                                     elasticNetParam=0.8)\n",
    "\n",
    "estimators_lr = \\\n",
    "  [continuous_feature_assembler, continuous_feature_scaler] \\\n",
    "  + categorical_feature_indexers + categorical_feature_one_hot_encoders \\\n",
    "  + [feature_assembler_lr] + [linear_regression]\n",
    "\n",
    "pipeline = Pipeline(stages=estimators_lr)\n",
    "\n",
    "pipeline_model = pipeline.fit(training_dataset)\n",
    "\n",
    "print(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 8**:  Serialize PipelineModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n",
      "<PMML xmlns=\"http://www.dmg.org/PMML-4_3\" version=\"4.3\">\n",
      "\t<Header>\n",
      "\t\t<Application/>\n",
      "\t\t<Timestamp>2017-03-21T01:50:49Z</Timestamp>\n",
      "\t</Header>\n",
      "\t<DataDictionary>\n",
      "\t\t<DataField name=\"bathrooms\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"bedrooms\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"security_deposit\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"cleaning_fee\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"extra_people\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"number_of_reviews\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"square_feet\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"review_scores_rating\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"room_type\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"Entire home/apt\"/>\n",
      "\t\t\t<Value value=\"Private room\"/>\n",
      "\t\t\t<Value value=\"Shared room\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"host_is_super_host\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"0.0\"/>\n",
      "\t\t\t<Value value=\"1.0\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"cancellation_policy\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"strict\"/>\n",
      "\t\t\t<Value value=\"moderate\"/>\n",
      "\t\t\t<Value value=\"flexible\"/>\n",
      "\t\t\t<Value value=\"super_strict_30\"/>\n",
      "\t\t\t<Value value=\"no_refunds\"/>\n",
      "\t\t\t<Value value=\"super_strict_60\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"instant_bookable\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"0.0\"/>\n",
      "\t\t\t<Value value=\"1.0\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"state\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"Other\"/>\n",
      "\t\t\t<Value value=\"NY\"/>\n",
      "\t\t\t<Value value=\"CA\"/>\n",
      "\t\t\t<Value value=\"Berlin\"/>\n",
      "\t\t\t<Value value=\"IL\"/>\n",
      "\t\t\t<Value value=\"TX\"/>\n",
      "\t\t\t<Value value=\"WA\"/>\n",
      "\t\t\t<Value value=\"DC\"/>\n",
      "\t\t\t<Value value=\"OR\"/>\n",
      "\t\t\t<Value value=\"London\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"price\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t</DataDictionary>\n",
      "\t<TransformationDictionary>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[0]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"bathrooms\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">2.069526648482131</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[1]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"bedrooms\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">1.1813357390856793</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[2]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"security_deposit\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.005511592151972438</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[3]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"cleaning_fee\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.023332951002159853</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[4]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"extra_people\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.053975458684955104</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[5]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"number_of_reviews\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.03702633373719701</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[6]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"square_feet\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.00284643019514287</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[7]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"review_scores_rating\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.11325940511789179</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t</TransformationDictionary>\n",
      "\t<RegressionModel functionName=\"regression\">\n",
      "\t\t<MiningSchema>\n",
      "\t\t\t<MiningField name=\"price\" usageType=\"target\"/>\n",
      "\t\t\t<MiningField name=\"bathrooms\"/>\n",
      "\t\t\t<MiningField name=\"bedrooms\"/>\n",
      "\t\t\t<MiningField name=\"security_deposit\"/>\n",
      "\t\t\t<MiningField name=\"cleaning_fee\"/>\n",
      "\t\t\t<MiningField name=\"extra_people\"/>\n",
      "\t\t\t<MiningField name=\"number_of_reviews\"/>\n",
      "\t\t\t<MiningField name=\"square_feet\"/>\n",
      "\t\t\t<MiningField name=\"review_scores_rating\"/>\n",
      "\t\t\t<MiningField name=\"room_type\"/>\n",
      "\t\t\t<MiningField name=\"host_is_super_host\"/>\n",
      "\t\t\t<MiningField name=\"cancellation_policy\"/>\n",
      "\t\t\t<MiningField name=\"instant_bookable\"/>\n",
      "\t\t\t<MiningField name=\"state\"/>\n",
      "\t\t</MiningSchema>\n",
      "\t\t<RegressionTable intercept=\"-34.26457784147972\">\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[0]\" coefficient=\"16.892397334749415\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[1]\" coefficient=\"21.03056845602723\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[2]\" coefficient=\"0.6920303344838707\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[3]\" coefficient=\"24.53382756971834\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[4]\" coefficient=\"2.4684594432921663\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[5]\" coefficient=\"-2.709392145295567\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[6]\" coefficient=\"4.6609133337401865\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[7]\" coefficient=\"4.456722174027065\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Entire home/apt\" coefficient=\"26.96911683791669\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Private room\" coefficient=\"-12.910890560688278\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"host_is_super_host\" value=\"0.0\" coefficient=\"-5.270523029322124\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"strict\" coefficient=\"2.505134511731441\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"moderate\" coefficient=\"-4.866795579439891\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"flexible\" coefficient=\"0.0\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"super_strict_30\" coefficient=\"67.19015082958964\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"no_refunds\" coefficient=\"0.0\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"instant_bookable\" value=\"0.0\" coefficient=\"6.945533583440488\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Other\" coefficient=\"-10.719304727842012\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"NY\" coefficient=\"20.673797130621836\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"CA\" coefficient=\"13.289832103895494\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Berlin\" coefficient=\"-49.53687895821985\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"IL\" coefficient=\"15.071737282592144\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"TX\" coefficient=\"33.33437844539034\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"WA\" coefficient=\"-8.186534576102213\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"DC\" coefficient=\"5.9024799046928065\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"OR\" coefficient=\"-17.0952074576551\"/>\n",
      "\t\t</RegressionTable>\n",
      "\t</RegressionModel>\n",
      "</PMML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jpmml import toPMMLBytes\n",
    "\n",
    "model_bytes = toPMMLBytes(spark, training_dataset, pipeline_model)\n",
    "\n",
    "print(model_bytes.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Push Model to Live, Running Spark ML Model Server (Mutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'airbnb'\n",
    "version = '1'\n",
    "update_url = 'http://prediction-pmml-aws.demo.pipeline.io/update-pmml-model/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'application/xml'\n",
    "\n",
    "req = urllib.request.Request(update_url, \\\n",
    "                             headers=update_headers, \\\n",
    "                             data=model_bytes)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.status) # Should return Http Status 200 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10:  Evalute Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"results\":[[{\\'price\\': \\'294.13434781225914\\'}]]}'\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'airbnb'\n",
    "version = '1'\n",
    "evaluate_url = 'http://prediction-pmml-aws.demo.pipeline.io/evaluate-pmml-model/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "\n",
    "input_params = '{\"bathrooms\":5.0, \\\n",
    "                 \"bedrooms\":4.0, \\\n",
    "                 \"security_deposit\":175.00, \\\n",
    "                 \"cleaning_fee\":25.0, \\\n",
    "                 \"extra_people\":1.0, \\\n",
    "                 \"number_of_reviews\": 2.0, \\\n",
    "                 \"square_feet\": 250.0, \\\n",
    "                 \"review_scores_rating\": 2.0, \\\n",
    "                 \"room_type\": \"Entire home/apt\", \\\n",
    "                 \"host_is_super_host\": \"0.0\", \\\n",
    "                 \"cancellation_policy\": \"flexible\", \\\n",
    "                 \"instant_bookable\": \"1.0\", \\\n",
    "                 \"state\": \"CA\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = urllib.request.Request(evaluate_url, \\\n",
    "                             headers=evaluate_headers, \\\n",
    "                             data=encoded_input_params)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Demos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Java-based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Java-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "sourceBytes = '                                                      \\n\\\n",
    "  private String str;                                                \\n\\\n",
    "                                                                     \\n\\\n",
    "  public void initialize(Map<String, Object> args) {                 \\n\\\n",
    "  }                                                                  \\n\\\n",
    "                                                                     \\n\\\n",
    "  public Object predict(Map<String, Object> inputs) {                \\n\\\n",
    "      String id = (String)inputs.get(\"id\");                          \\n\\\n",
    "                                                                     \\n\\\n",
    "      return id.equals(\"21619\");                                     \\n\\\n",
    "  }                                                                  \\n\\\n",
    "'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Java-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* 001 */\n",
      "/* 002 */ private String str;\n",
      "/* 003 */\n",
      "/* 004 */ public void initialize(Map<String, Object> args) {\n",
      "/* 005 */ }\n",
      "/* 006 */\n",
      "/* 007 */ public Object predict(Map<String, Object> inputs) {\n",
      "/* 008 */   String id = (String)inputs.get(\"id\");\n",
      "/* 009 */\n",
      "/* 010 */   return id.equals(\"21619\");\n",
      "/* 011 */ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'java_equals'\n",
    "version = '1'\n",
    "\n",
    "update_url = 'http://prediction-java-aws.demo.pipeline.io/update-java/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Java-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'false'\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'java_equals'\n",
    "version = '1'\n",
    "\n",
    "evaluate_url = 'http://prediction-java-aws.demo.pipeline.io/evaluate-java/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"id\":\"21618\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return false "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'true'\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'java_equals'\n",
    "version = '1'\n",
    "evaluate_url = 'http://prediction-java-aws.demo.pipeline.io/evaluate-java/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"id\":\"21619\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Scikit-Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn_pandas\r\n",
      "  Downloading sklearn_pandas-1.3.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: pandas>=0.11.0 in /opt/conda/lib/python3.5/site-packages (from sklearn_pandas)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.5/site-packages (from sklearn_pandas)\r\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /opt/conda/lib/python3.5/site-packages (from sklearn_pandas)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.5/site-packages (from sklearn_pandas)\r\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.5/site-packages (from pandas>=0.11.0->sklearn_pandas)\r\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.5/site-packages (from pandas>=0.11.0->sklearn_pandas)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.5/site-packages (from python-dateutil>=2->pandas>=0.11.0->sklearn_pandas)\r\n",
      "Installing collected packages: sklearn-pandas\r\n",
      "Successfully installed sklearn-pandas-1.3.0\r\n",
      "Collecting git+https://github.com/jpmml/sklearn2pmml.git\r\n",
      "  Cloning https://github.com/jpmml/sklearn2pmml.git to /tmp/pip-pw2nvpqe-build\r\n",
      "Requirement already satisfied: scikit-learn>=0.16.0 in /opt/conda/lib/python3.5/site-packages (from sklearn2pmml==0.17.4)\r\n",
      "Requirement already satisfied: sklearn_pandas>=0.0.10 in /opt/conda/lib/python3.5/site-packages (from sklearn2pmml==0.17.4)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.5/site-packages (from sklearn_pandas>=0.0.10->sklearn2pmml==0.17.4)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.5/site-packages (from sklearn_pandas>=0.0.10->sklearn2pmml==0.17.4)\r\n",
      "Requirement already satisfied: pandas>=0.11.0 in /opt/conda/lib/python3.5/site-packages (from sklearn_pandas>=0.0.10->sklearn2pmml==0.17.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.5/site-packages (from pandas>=0.11.0->sklearn_pandas>=0.0.10->sklearn2pmml==0.17.4)\r\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.5/site-packages (from pandas>=0.11.0->sklearn_pandas>=0.0.10->sklearn2pmml==0.17.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.5/site-packages (from python-dateutil>=2->pandas>=0.11.0->sklearn_pandas>=0.0.10->sklearn2pmml==0.17.4)\r\n",
      "Installing collected packages: sklearn2pmml\r\n",
      "  Running setup.py install for sklearn2pmml ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hSuccessfully installed sklearn2pmml-0.17.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_pandas\n",
    "!pip install git+https://github.com/jpmml/sklearn2pmml.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scikit-Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PMMLPipeline(steps=[('classifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "from sklearn.datasets import load_diabetes,load_iris\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse, r2_score\n",
    "from sklearn2pmml import PMMLPipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "iris_df['Species'] = iris.target\n",
    "iris_pipeline = PMMLPipeline([\n",
    "    (\"classifier\", DecisionTreeClassifier())\n",
    "])\n",
    "iris_pipeline.fit(iris_df[iris_df.columns.difference([\"Species\"])], iris_df[\"Species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize Scikit-Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn2pmml(iris_pipeline, \"DecisionTreeIris.pmml\", with_repr = True)\n",
    "model_bytes = bytearray(open('DecisionTreeIris.pmml', 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Scikit-Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'iris'\n",
    "version = '1'\n",
    "\n",
    "update_url = 'http://prediction-pmml-aws.demo.pipeline.io/update-pmml-model/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "update_headers = {}\n",
    "update_headers[\"Content-type\"] = \"application/xml\"\n",
    "\n",
    "req = urllib.request.Request(update_url, headers=update_headers, data=model_bytes)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "print(resp.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"results\":[{\"result\": \"fallback\"}]}'\n"
     ]
    }
   ],
   "source": [
    "namespace = 'default'\n",
    "model_name = 'iris'\n",
    "version = '1'\n",
    "\n",
    "evaluate_url = 'http://prediction-pmml-aws.demo.pipeline.io/evaluate-pmml-model/%s/%s/%s' % (namespace, model_name, version)\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "\n",
    "input_params = iris_df.ix[0,:-1].to_json()\n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = urllib.request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Your Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netflix Microservices [Dashboard](http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D) (Hystrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=1200px height=500px src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=1200px height=500px src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafana + Prometheus [Dashboard](http://grafana.demo.pipeline.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=1200px height=500px src=\"http://grafana.demo.pipeline.io\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=1200px height=500px src=\"http://grafana.demo.pipeline.io\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load-Test Your Model Servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run JMeter Tests from Local Laptop (Limited by Laptop Performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Headless JMeter Tests from Training Clusters in Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark ML - Airbnb\n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-airbnb-rc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codegen - Java - Simple\n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-equals-rc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow AI - Tensorflow Serving - Simple \n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-minimal-rc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Load Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete --context=awsdemo rc loadtest-aws-airbnb\n",
    "!kubectl delete --context=awsdemo rc loadtest-aws-equals\n",
    "!kubectl delete --context=awsdemo rc loadtest-aws-minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!kubectl rolling-update prediction-tensorflow --context=awsdemo --image-pull-policy=Always --image=fluxcapacitor/prediction-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PipelineIO Premium Edition\n",
    "\n",
    "![PipelineIO](http://pipeline.io/images/pipeline-io-logo-shadow-210x186.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B and Multi-armed Bandit Testing\n",
    "\n",
    "![A/B Testing](http://pipeline.io/images/ab-testing-170x100.png)\n",
    "![Multi-armed Bandit](http://pipeline.io/images/multi-armed-bandit-101x100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous, Hybrid-Cloud Deployments\n",
    "![AWS](http://pipeline.io/images/aws-logo-185x73.png)\n",
    "![Google](http://pipeline.io/images/gce-logo-190x90.png)\n",
    "![Azure](http://pipeline.io/images/azure-logo-200x103.png)\n",
    "![Kubernetes](http://pipeline.io/images/kubernetes-logo-200x171.png)\n",
    "![Docker](http://pipeline.io/images/docker-logo-150x126.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Model Training and Deploying\n",
    "\n",
    "![Kafka](http://pipeline.io/images/kafka-logo-wide-219x98.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU-based Deployments\n",
    "\n",
    "![CUDA](http://pipeline.io/images/nvidia-cuda-338x181.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
