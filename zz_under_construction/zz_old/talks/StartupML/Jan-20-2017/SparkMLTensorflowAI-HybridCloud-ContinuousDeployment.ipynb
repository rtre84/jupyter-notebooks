{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where Am I?\n",
    "\n",
    "## Startup.ML Conference - San Francisco - Jan 20, 2017\n",
    "![StartupML Conference](https://s3.amazonaws.com/fluxcapacitor.com/img/startup-ml-conf-01-21-2017-san-francisco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fcb54439-1c2c-46ce-9d92-e77df43393db"
    }
   },
   "source": [
    "# Who Am I?\n",
    "## Chris Fregly\n",
    "\n",
    "![Chris Fregly](https://s3.amazonaws.com/fluxcapacitor.com/img/fregly-300x300.png)\n",
    "\n",
    "![Chris Fregly Emoji](https://s3.amazonaws.com/fluxcapacitor.com/img/fregly-emoji-300x300.png)\n",
    "### Research Scientist @ **[PipelineIO](http://pipeline.io)** \n",
    "\n",
    "![PipelineIO](http://pipeline.io/images/pipeline-io-logo-shadow-210x186.png)\n",
    "\n",
    "### Video Series Author \"High Performance Tensorflow in Production\" @ [OReilly](http://oreilly.com) (Coming Soon)\n",
    "\n",
    "![OReilly Media](https://s3.amazonaws.com/fluxcapacitor.com/img/oreilly-logo.png)\n",
    "\n",
    "### Founder @ **[Advanced Spark and Tensorflow Meetup](http://http://www.meetup.com/Advanced-Spark-and-TensorFlow-Meetup/)**\n",
    "\n",
    "![Advanced Spark and Tensorflow Meetup](https://s3.amazonaws.com/fluxcapacitor.com/img/advanced-spark-tensorflow-meetup-logo-green.png)\n",
    "\n",
    "### **[Github Repo](https://github.com/fluxcapacitor/pipeline)**\n",
    "\t\n",
    "![Github Repo](https://s3.amazonaws.com/fluxcapacitor.com/img/pipeline-io-github-1000-stars.png)\n",
    "\n",
    "### **[DockerHub Repo](https://hub.docker.com/u/fluxcapacitor/)**\n",
    "\n",
    "![DockerHub](https://s3.amazonaws.com/fluxcapacitor.com/img/dockerhub-logo.png)\n",
    "\n",
    "### **[Slideshare](http://www.slideshare.net/cfregly)**\n",
    "\n",
    "![Slideshare](http://advancedspark.com/img/slideshare.png)\n",
    "\n",
    "### **[YouTube](https://www.youtube.com/playlist?list=PL7pBcJ870QHeNRBXdKirc4fdtbtbB5Xy-)**\n",
    "\n",
    "![YouTube](http://advancedspark.com/img/youtube-300x134.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Was I?\n",
    "### Software Engineer @ **Netflix**, **Databricks**, **IBM Spark Tech Center**\n",
    "\n",
    "![Netflix](http://pipeline.io/images/netflixoss-logo-white-295x55.png) \n",
    "\n",
    "![Databricks](http://pipeline.io/images/databricks-logo-350x69.png) \n",
    "\n",
    "![IBM Spark Tech Center](https://s3.amazonaws.com/fluxcapacitor.com/img/ibm-spark-logo-197x148.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "023050ea-c894-4ffe-869f-2f27f03e524a"
    }
   },
   "source": [
    "# 1. Infrastructure and Tools\n",
    "### Docker\n",
    "Images, Containers\n",
    "\n",
    "Useful Docker Image:  **[AWS + GPU + Docker + Tensorflow + Spark](https://github.com/fluxcapacitor/pipeline/wiki/AWS-GPU-TensorFlow-Docker)**\n",
    "\n",
    "![Docker](http://pipeline.io/images/docker-logo-150x126.png)\n",
    "\n",
    "### Kubernetes\n",
    "Container Orchestration Across Clusters\n",
    "\n",
    "![Kubernetes](http://pipeline.io/images/kubernetes-logo-200x171.png) \n",
    "\n",
    "### Weavescope\n",
    "Kubernetes Cluster Visualization\n",
    "\n",
    "![PipelineIO Kubernetes](https://s3.amazonaws.com/fluxcapacitor.com/img/weavescope-pipelineio.png)\n",
    "\n",
    "### Jupyter Notebooks\n",
    "What We're Using Here for Everything!\n",
    "\n",
    "![Jupyter](http://pipeline.io/images/jupyter-logo-105x106.png) \n",
    "\n",
    "### Airflow\n",
    "Invoke Any Type of Workflow on Any Type of Schedule \n",
    "\n",
    "![Airflow](https://s3.amazonaws.com/fluxcapacitor.com/img/airflow-continuous-deployment.png)\n",
    " \n",
    "### Github\n",
    "Commit New Model to Github, Airflow Workflow Triggered for Continuous Deployment \n",
    "\t\n",
    "![Github Repo](https://s3.amazonaws.com/fluxcapacitor.com/img/pipeline-io-github-1000-stars.png)\n",
    "\n",
    "### DockerHub\n",
    "Maintains Docker Images \n",
    "\n",
    "![DockerHub](https://s3.amazonaws.com/fluxcapacitor.com/img/dockerhub-logo.png)\n",
    "\n",
    "### Continuous Deployment\n",
    "Not Just for Code, Also for ML/AI Models!\n",
    "\n",
    "### Canary Release\n",
    "Deploy and Compare New Model Alongside Existing\n",
    "\n",
    "### Metrics and Dashboards\n",
    "Not Just System Metrics, ML/AI Model Prediction Metrics\n",
    "\n",
    "NetflixOSS-based\n",
    "\n",
    "Prometheus\n",
    "\n",
    "Grafana\n",
    "\n",
    "Elasticsearch\n",
    "\n",
    "### Separate Cluster Concerns\n",
    "Training/Admin Cluster\n",
    "\n",
    "Prediction Cluster\n",
    "\n",
    "### Hybrid Cloud Deployment for eXtreme High Availability (XHA)\n",
    "AWS and Google Cloud\n",
    "\n",
    "### Apache Spark\n",
    "![Spark](http://pipeline.io/images/spark-logo-150x78.png) \n",
    "\n",
    "### Tensorflow + Tensorflow Serving\n",
    "![Tensorflow](http://pipeline.io/images/tensorflow-logo-150x128.png)\n",
    "\n",
    "![Architecture](https://s3.amazonaws.com/fluxcapacitor.com/img/tensorflow-serving-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ca731c95-6e39-4db8-a51c-f467a315616d"
    }
   },
   "source": [
    "# 2. Model Deployment Bundles\n",
    "### KeyValue\n",
    "ie. Recommendations\n",
    "\n",
    "In-memory: Redis, Memcache\n",
    "\n",
    "On-disk:  Cassandra, RocksDB\n",
    "\n",
    "First-class Servable in [Tensorflow Serving](https://github.com/tensorflow/serving/tree/master/tensorflow_serving/servables)\n",
    "\n",
    "### PMML\n",
    "It's Useful and [Well-Supported](https://github.com/jpmml)\n",
    "\n",
    "Apple, Cisco, [Airbnb](http://nerds.airbnb.com/architecting-machine-learning-system-risk/), HomeAway, etc\n",
    "\n",
    "Please Don't Re-build It - Reduce Your Technical Debt!\n",
    "\n",
    "![Regression Model PMML](https://s3.amazonaws.com/fluxcapacitor.com/img/regression-model-pmml2.png)\n",
    "\n",
    "### Native Code\n",
    "Hand-coded (Python + Pickling)\n",
    "\n",
    "Generate Java Code from PMML?\n",
    "\n",
    "![Regression Model Java Codegen](https://s3.amazonaws.com/fluxcapacitor.com/img/regression-model-codegen2.png)\n",
    "\n",
    "### Tensorflow Model Exports\n",
    "[freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py): Combine Tensorflow Graph (Static) with Trained Weights (Checkpoints) into Single Deployable Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a0dd485d-6cdf-4ccc-ba0c-60b2ed06bac7"
    }
   },
   "source": [
    "# 3. Model Deployments and Rollbacks\n",
    "### Mutable\n",
    "Each New Model is Deployed to Live, Running Container\n",
    "\n",
    "### Immutable\n",
    "Each New Model is a New Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optimizing Tensorflow Models for Serving\n",
    "## Python Scripts\n",
    "[optimize_graph_for_inference.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py)\n",
    "\n",
    "[Pete Warden's Blog](https://petewarden.com/2016/12/30/rewriting-tensorflow-graphs-with-the-gtt/)\n",
    "\n",
    "[Graph Transform Tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md)\n",
    "\n",
    "\n",
    "## Compile (Tensorflow 1.0+)\n",
    "### [XLA](https://www.tensorflow.org/versions/master/experimental/xla/) Compiler\n",
    "Compiles 3 graph operations (input, operation, output) into 1 operation\n",
    "\n",
    "Removes need for Tensorflow Runtime (20 MB is significant on tiny devices)\n",
    "\n",
    "Allows new backends for hardware-specific optimizations (better portability)\n",
    "\n",
    "### [tfcompile](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/aot)\n",
    "Convert Graph into executable code\n",
    "\n",
    "### Compress/Distill Ensemble Models\n",
    "Convert ensembles or other complex models into smaller models\n",
    "\n",
    "Re-score training data with output of model being distilled \n",
    "\n",
    "Train smaller model to produce same output\n",
    "\n",
    "Output of smaller model learns more information than original label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimizing Serving Runtime Environment\n",
    "### Throughput\n",
    "**Option 1**:  Add more Tensorflow Serving servers behind **load balancer**\n",
    "\n",
    "**Option 2**:  Enable **request batching** in each Tensorflow Serving\n",
    "\n",
    "**Option Trade-offs**:  Higher Latency (bad) for Higher Throughput (good)\n",
    "\n",
    "```\n",
    "$TENSORFLOW_SERVING_HOME/bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \n",
    "--port=9000 \n",
    "--model_name=tensorflow_minimal \n",
    "--model_base_path=/root/models/tensorflow_minimal/export\n",
    "--enable_batching=true\n",
    "--max_batch_size=1000000\n",
    "--batch_timeout_micros=10000\n",
    "--max_enqueued_batches=1000000\n",
    "```\n",
    "![Request Batching](https://s3.amazonaws.com/fluxcapacitor.com/img/matrix-multiply-request-batching-handwritten.png)\n",
    "\n",
    "### Latency\n",
    "The deeper the model, the longer the latency\n",
    "\n",
    "Start inference in parallel where possible (ie. user inference in parallel with item inference)\n",
    "\n",
    "Pre-load common inputs from database (ie. user attributes, item attributes) \n",
    "\n",
    "Pre-compute/partial-compute common inputs (ie. popular word embeddings)\n",
    "\n",
    "### Memory\n",
    "Word embeddings are **huge**!\n",
    "\n",
    "Use **hashId** for each word\n",
    "\n",
    "Off-load embedding matrices to **parameter server** and share between serving servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Demos!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Deploy Tensorflow AI Model (Simple Model, Immutable Deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Tensorflow AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make things wide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def=None, width=1200, height=800, max_const_size=32, ungroup_gradients=False):\n",
    "    if not graph_def:\n",
    "        graph_def = tf.get_default_graph().as_graph_def()\n",
    "        \n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    data = str(strip_def)\n",
    "    if ungroup_gradients:\n",
    "        data = data.replace('\"gradients/', '\"b_')\n",
    "        #print(data)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(data), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:{}px;height:{}px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(width, height, code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If this errors out, increment the `export_version` variable, restart the Kernel, and re-run\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer(\"batch_size\", 10, \"The batch size to train\")\n",
    "flags.DEFINE_integer(\"epoch_number\", 10, \"Number of epochs to run trainer\")\n",
    "flags.DEFINE_integer(\"steps_to_validate\", 1,\n",
    "                     \"Steps to validate and print loss\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"./checkpoint/\",\n",
    "                    \"indicates the checkpoint dirctory\")\n",
    "#flags.DEFINE_string(\"model_path\", \"./model/\", \"The export path of the model\")\n",
    "flags.DEFINE_string(\"model_path\", \"/root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/\", \"The export path of the model\")\n",
    "#flags.DEFINE_integer(\"export_version\", 27, \"The version number of the model\")\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "seconds_since_epoch = int(datetime.now().strftime(\"%s\"))\n",
    "\n",
    "export_version = seconds_since_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 1 for 'MatMul_1' (op: 'MatMul') with input shapes: [?], [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 1 for 'MatMul_1' (op: 'MatMul') with input shapes: [?], [1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1856d87b036a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1856d87b036a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mpredict_op\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1765\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   1452\u001b[0m   \"\"\"\n\u001b[1;32m   1453\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[0;32m-> 1454\u001b[0;31m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1455\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    761\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    762\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2327\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2330\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1715\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 2 but is rank 1 for 'MatMul_1' (op: 'MatMul') with input shapes: [?], [1]."
     ]
    }
   ],
   "source": [
    "# If this errors out, increment the `export_version` variable, restart the Kernel, and re-run\n",
    "\n",
    "def main():\n",
    "  # Define training data\n",
    "  x = np.ones(FLAGS.batch_size)\n",
    "  y = np.ones(FLAGS.batch_size)\n",
    "\n",
    "  # Define the model\n",
    "  X = tf.placeholder(tf.float32, shape=[None], name=\"X\")\n",
    "  Y = tf.placeholder(tf.float32, shape=[None], name=\"yhat\")\n",
    "  w = tf.Variable([1.0], name=\"weight\")\n",
    "  b = tf.Variable([1.0], name=\"bias\")\n",
    "  loss = tf.square(Y - tf.matmul(X, w) - b)\n",
    "  train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "  predict_op  = tf.mul(X, w) + b\n",
    "\n",
    "  saver = tf.train.Saver()\n",
    "  checkpoint_dir = FLAGS.checkpoint_dir\n",
    "  checkpoint_file = checkpoint_dir + \"/checkpoint.ckpt\"\n",
    "  if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "  # Start the session\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      print(\"Continue training from the model {}\".format(ckpt.model_checkpoint_path))\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    saver_def = saver.as_saver_def()\n",
    "    print(saver_def.filename_tensor_name)\n",
    "    print(saver_def.restore_op_name)\n",
    "\n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    for epoch in range(FLAGS.epoch_number):\n",
    "      sess.run(train_op, feed_dict={X: x, Y: y})\n",
    "\n",
    "      # Start validating\n",
    "      if epoch % FLAGS.steps_to_validate == 0:\n",
    "        end_time = time.time()\n",
    "        print(\"[{}] Epoch: {}\".format(end_time - start_time, epoch))\n",
    "\n",
    "        saver.save(sess, checkpoint_file)\n",
    "        tf.train.write_graph(sess.graph_def, checkpoint_dir, 'trained_model.pb', as_text=False)\n",
    "        tf.train.write_graph(sess.graph_def, checkpoint_dir, 'trained_model.txt', as_text=True)\n",
    "\n",
    "        start_time = end_time\n",
    "\n",
    "    # Print model variables\n",
    "    w_value, b_value = sess.run([w, b])\n",
    "    print(\"The model of w: {}, b: {}\".format(w_value, b_value))\n",
    "\n",
    "    # Export the model\n",
    "    print(\"Exporting trained model to {}\".format(FLAGS.model_path))\n",
    "    model_exporter = exporter.Exporter(saver)\n",
    "    model_exporter.init(\n",
    "      sess.graph.as_graph_def(),\n",
    "      named_graph_signatures={\n",
    "        'inputs': exporter.generic_signature({\"features\": X}),\n",
    "        'outputs': exporter.generic_signature({\"prediction\": predict_op})\n",
    "      })\n",
    "    model_exporter.export(FLAGS.model_path, tf.constant(export_version), sess)\n",
    "    print('Done exporting!')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit and Deploy New Tensorflow AI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit Model to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 19 22:39 00000001\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 20:09 00000005\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:24 00000007\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:30 00000009\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:35 00000011\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 21:36 00000013\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 22:02 00000015\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 21 22:18 00000017\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 22 00:00 00000019\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 22 05:15 00000021\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 22 06:49 00000025\r\n",
      "drwxr-xr-x 2 root root 4096 Jan 25 20:55 00000027\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "-rw-r--r-- 1 root root   241 Jan 25 20:55 checkpoint\r\n",
      "-rw-r--r-- 1 root root     8 Jan 25 20:55 export.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root   142 Jan 25 20:55 export.index\r\n",
      "-rw-r--r-- 1 root root 19394 Jan 25 20:55 export.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "\r\n",
      "Changes to be committed:\r\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\r\n",
      "\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/checkpoint\u001b[m\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.data-00000-of-00001\u001b[m\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.index\u001b[m\r\n",
      "\t\u001b[32mnew file:   ../../../../../prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.meta\u001b[m\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   SparkMLTensorflowAI-HybridCloud-ContinuousDeployment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../TensorFlow/DeepDream/deepdream.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Theano/Model Save and Load.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mSparkMLTensorflowAI-HybridCloud-ContinuousDeployment-Copy1.ipynb\u001b[m\r\n",
      "\t\u001b[31mcheckpoint/\u001b[m\r\n",
      "\t\u001b[31m../../../TimeSeries/Untitled.ipynb\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!git add --all /root/pipeline/prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is ahead of 'origin/master' by 1 commit.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   SparkMLTensorflowAI-HybridCloud-ContinuousDeployment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Scikit-Learn/Scikit-Learn+Demos.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../TensorFlow/DeepDream/deepdream.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Theano/Model Save and Load.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mSparkMLTensorflowAI-HybridCloud-ContinuousDeployment-Azure.ipynb\u001b[m\r\n",
      "\t\u001b[31mcheckpoint/\u001b[m\r\n",
      "\t\u001b[31m../../../Spark/Pi/\u001b[m\r\n",
      "\t\u001b[31m../../../TimeSeries/Untitled.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 0ce7882] updated tensorflow model\r\n",
      " 4 files changed, 2 insertions(+)\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/checkpoint\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.data-00000-of-00001\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.index\r\n",
      " create mode 100644 prediction.ml/tensorflow/models/tensorflow_minimal/export/00000027/export.meta\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"updated tensorflow model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "\r\n",
      "Changes to be committed:\r\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\r\n",
      "\r\n",
      "\t\u001b[32mmodified:   ../../../../scripts/pi.py\u001b[m\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   SparkMLTensorflowAI-HybridCloud-ContinuousDeployment.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Scikit-Learn/Scikit-Learn+Demos.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../TensorFlow/DeepDream/deepdream.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../../../Theano/Model Save and Load.ipynb\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mSparkMLTensorflowAI-HybridCloud-ContinuousDeployment-Azure.ipynb\u001b[m\r\n",
      "\t\u001b[31mcheckpoint/\u001b[m\r\n",
      "\t\u001b[31m../../../Spark/Pi/\u001b[m\r\n",
      "\t\u001b[31m../../../TimeSeries/Untitled.ipynb\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: push.default is unset; its implicit value is changing in\n",
      "Git 2.0 from 'matching' to 'simple'. To squelch this message\n",
      "and maintain the current behavior after the default changes, use:\n",
      "\n",
      "  git config --global push.default matching\n",
      "\n",
      "To squelch this message and adopt the new behavior now, use:\n",
      "\n",
      "  git config --global push.default simple\n",
      "\n",
      "When push.default is set to 'matching', git will push local branches\n",
      "to the remote branches that already exist with the same name.\n",
      "\n",
      "In Git 2.0, Git will default to the more conservative 'simple'\n",
      "behavior, which only pushes the current branch to the corresponding\n",
      "remote branch that 'git pull' uses to update the current branch.\n",
      "\n",
      "See 'git help config' and search for 'push.default' for further information.\n",
      "(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode\n",
      "'current' instead of 'simple' if you sometimes use older versions of Git)\n",
      "\n",
      "Permission denied (publickey).\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n"
     ]
    }
   ],
   "source": [
    "# If this fails with \"Permission denied\", use terminal within jupyter to manually `git push`\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Airflow Workflow](http://demo.pipeline.io:8080/admin/) Deploys New Model through Github Post-Commit [Webhook](https://github.com/fluxcapacitor/pipeline/blob/master/scheduler.ml/airflow/github_webhook) to Triggers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=100% height=500px src=\"http://demo.pipeline.io:8080/admin\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=100% height=500px src=\"http://demo.pipeline.io:8080/admin\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Deploy Spark ML Model (Airbnb Model, Mutable Deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Out Spark Training Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes [CLI](https://github.com/fluxcapacitor/pipeline/wiki/Kubernetes-Commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replicationcontroller \"spark-worker-2-0-1\" scaled\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl scale --context=awsdemo --replicas=2 rc spark-worker-2-0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                           READY     STATUS    RESTARTS   AGE\r\n",
      "airflow-z2txg                                                  1/1       Running   0          51m\r\n",
      "hdfs-gd1pf                                                     1/1       Running   0          11d\r\n",
      "hystrix-rdx5g                                                  1/1       Running   0          9d\r\n",
      "jupyterhub-master-sqqjf                                        1/1       Running   0          11d\r\n",
      "metastore-1-2-1-jw8kx                                          1/1       Running   0          11d\r\n",
      "mysql-master-586zp                                             1/1       Running   0          11d\r\n",
      "prediction-codegen-b8c5b3016dc1eb4e655146be94cd2d56-p5m8f      1/1       Running   0          9d\r\n",
      "prediction-pmml-7db0fe5cbac0a14d38069985acd5b119-jv3ln         1/1       Running   0          9d\r\n",
      "prediction-tensorflow-60175981688eb64d9663a29c3ced8f45-4zndp   1/1       Running   0          9d\r\n",
      "spark-master-2-0-1-28vrg                                       1/1       Running   0          11d\r\n",
      "spark-worker-2-0-1-49qqg                                       1/1       Running   0          11d\r\n",
      "spark-worker-2-0-1-56hqq                                       1/1       Running   0          5d\r\n",
      "turbine-2gvb2                                                  1/1       Running   0          9d\r\n",
      "weavescope-app-c9khj                                           1/1       Running   0          11d\r\n",
      "weavescope-probe-0mtn7                                         1/1       Running   0          11d\r\n",
      "weavescope-probe-7qtz4                                         1/1       Running   0          11d\r\n",
      "weavescope-probe-kqt3z                                         1/1       Running   0          11d\r\n",
      "web-home-0c9jw                                                 1/1       Running   0          11d\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod --context=awsdemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weavescope Kubernetes [AWS Cluster](http://kubernetes-aws.demo.pipeline.io) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=100% height=500px src=\"http://kubernetes-aws.demo.pipeline.io\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=100% height=500px src=\"http://kubernetes-aws.demo.pipeline.io\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PMML from Spark ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--master spark://spark-master-2-1-0:7077 --conf spark.cores.max=1 --conf spark.executor.memory=512m --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1 --jars /root/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar --py-files /root/lib/jpmml.py pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "# You may need to Reconnect (more than Restart) the Kernel to pick up changes to these sett\n",
    "import os\n",
    "\n",
    "master = '--master spark://spark-master-2-1-0:7077'\n",
    "conf = '--conf spark.cores.max=1 --conf spark.executor.memory=512m'\n",
    "packages = '--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1'\n",
    "jars = '--jars /root/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar'\n",
    "py_files = '--py-files /root/lib/jpmml.py'\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = master \\\n",
    "  + ' ' + conf \\\n",
    "  + ' ' + packages \\\n",
    "  + ' ' + jars \\\n",
    "  + ' ' + py_files \\\n",
    "  + ' ' + 'pyspark-shell'\n",
    "\n",
    "print(os.environ['PYSPARK_SUBMIT_ARGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 0**: Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=5731498, name='A 2-bdrm house in Plaka of Athens', space='Ideally located a unique house in a very peaceful neighborhood of Plaka, near Acropolis. It is a traditional house in the heart of the historical center of Athens, in Plaka. The kitchen is fully equipped with oven, fridge with freezer. Cutlery, dishes and pans, kettle, espresso coffee maker (espresso capsules are provided), toaster. There is also a vacuum cleaner and a laundry machine. One big closet will make your stay more comfortable. Bed linen, towels and bath amenities are provided. Moreover, the apartment is fully airconditioned. The apartment is very close to a greek traditional tavernas, a pharmacy, banks and public transport.  Airport or any other transport is available upon demand at an additional but very reasonable cost. ', price='120.0', bathrooms='1.0', bedrooms='2.0', room_type='Entire home/apt', square_feet=None, host_is_super_host='0.0', city='Athina', state=None, cancellation_policy='moderate', security_deposit='200.0', cleaning_fee='20.0', extra_people='15.0', minimum_nights='2', first_review='2015-04-07', instant_bookable='1.0', number_of_reviews='16', review_scores_rating='94.0', price_per_bedroom='60.0')\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "  .option(\"inferSchema\", \"true\").option(\"header\", \"true\") \\\n",
    "  .load(\"s3a://datapalooza/airbnb/airbnb.csv.bz2\")\n",
    "\n",
    "df.registerTempTable(\"df\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198576\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Clean, Filter, and Summarize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|summary|      square_feet|             price|          bedrooms|         bathrooms|      cleaning_fee|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|  count|           151864|            151864|            151864|            151864|            151864|\n",
      "|   mean|545.5920823895063|131.00769109202972|1.3336998893747036|1.1988786019069695| 37.25118527103198|\n",
      "| stddev| 363.234618108484| 89.59372969879456|0.8460907193971745|0.4836515839573292|42.625502170779164|\n",
      "|    min|            104.0|              50.0|               0.0|               0.5|               0.0|\n",
      "|    max|          32292.0|             750.0|              10.0|               8.0|             700.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(\"price >= 50 AND price <= 750 AND bathrooms > 0.0 AND bedrooms is not null\")\n",
    "\n",
    "df_filtered.registerTempTable(\"df_filtered\")\n",
    "\n",
    "df_final = spark.sql(\"\"\"\n",
    "    select\n",
    "        id,\n",
    "        city,\n",
    "        case when state in('NY', 'CA', 'London', 'Berlin', 'TX' ,'IL', 'OR', 'DC', 'WA')\n",
    "            then state\n",
    "            else 'Other'\n",
    "        end as state,\n",
    "        space,\n",
    "        cast(price as double) as price,\n",
    "        cast(bathrooms as double) as bathrooms,\n",
    "        cast(bedrooms as double) as bedrooms,\n",
    "        room_type,\n",
    "        host_is_super_host,\n",
    "        cancellation_policy,\n",
    "        cast(case when security_deposit is null\n",
    "            then 0.0\n",
    "            else security_deposit\n",
    "        end as double) as security_deposit,\n",
    "        price_per_bedroom,\n",
    "        cast(case when number_of_reviews is null\n",
    "            then 0.0\n",
    "            else number_of_reviews\n",
    "        end as double) as number_of_reviews,\n",
    "        cast(case when extra_people is null\n",
    "            then 0.0\n",
    "            else extra_people\n",
    "        end as double) as extra_people,\n",
    "        instant_bookable,\n",
    "        cast(case when cleaning_fee is null\n",
    "            then 0.0\n",
    "            else cleaning_fee\n",
    "        end as double) as cleaning_fee,\n",
    "        cast(case when review_scores_rating is null\n",
    "            then 80.0\n",
    "            else review_scores_rating\n",
    "        end as double) as review_scores_rating,\n",
    "        cast(case when square_feet is not null and square_feet > 100\n",
    "            then square_feet\n",
    "            when (square_feet is null or square_feet <=100) and (bedrooms is null or bedrooms = 0)\n",
    "            then 350.0\n",
    "            else 380 * bedrooms\n",
    "        end as double) as square_feet\n",
    "    from df_filtered\n",
    "\"\"\").persist()\n",
    "\n",
    "df_final.registerTempTable(\"df_final\")\n",
    "\n",
    "df_final.select(\"square_feet\", \"price\", \"bedrooms\", \"bathrooms\", \"cleaning_fee\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151864\n"
     ]
    }
   ],
   "source": [
    "print(df_final.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(id,IntegerType,true),StructField(city,StringType,true),StructField(state,StringType,true),StructField(space,StringType,true),StructField(price,DoubleType,true),StructField(bathrooms,DoubleType,true),StructField(bedrooms,DoubleType,true),StructField(room_type,StringType,true),StructField(host_is_super_host,StringType,true),StructField(cancellation_policy,StringType,true),StructField(security_deposit,DoubleType,true),StructField(price_per_bedroom,StringType,true),StructField(number_of_reviews,DoubleType,true),StructField(extra_people,DoubleType,true),StructField(instant_bookable,StringType,true),StructField(cleaning_fee,DoubleType,true),StructField(review_scores_rating,DoubleType,true),StructField(square_feet,DoubleType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(df_final.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+---------+\n",
      "| state|   ct|         avg_price|max_price|\n",
      "+------+-----+------------------+---------+\n",
      "| Other|87467|122.00503046863389|    750.0|\n",
      "|    NY|22899| 145.9446264028997|    750.0|\n",
      "|    CA|20750|157.40173493975902|    750.0|\n",
      "|Berlin| 6034|  80.6433543254889|    650.0|\n",
      "|    IL| 3552|141.46903153153153|    690.0|\n",
      "|    TX| 3108|195.25611325611325|    750.0|\n",
      "|    WA| 2700| 131.4962962962963|    750.0|\n",
      "|    DC| 2590|136.64015444015445|    720.0|\n",
      "|    OR| 1954|114.02661207778915|    700.0|\n",
      "|London|  810|108.84444444444445|    600.0|\n",
      "+------+-----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most popular cities\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select \n",
    "        state,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by state\n",
    "    order by count(*) desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------------+---------+\n",
      "|               city| ct|         avg_price|max_price|\n",
      "+-------------------+---+------------------+---------+\n",
      "|         Palm Beach| 26| 348.7692307692308|    701.0|\n",
      "|        Watsonville| 38| 313.3157894736842|    670.0|\n",
      "|             Malibu|136| 280.9852941176471|    750.0|\n",
      "|             Avalon| 38|262.42105263157896|    701.0|\n",
      "|           Capitola| 35|             246.4|    650.0|\n",
      "|           Tamarama| 72|             238.5|    750.0|\n",
      "|    Manhattan Beach|109|232.10091743119267|    700.0|\n",
      "|Rancho Palos Verdes| 39|230.02564102564102|    750.0|\n",
      "|       Avalon Beach| 38|229.60526315789474|    620.0|\n",
      "|            Newport| 52| 223.8653846153846|    750.0|\n",
      "|      Darling Point| 29|221.51724137931035|    623.0|\n",
      "|        Middle Park| 34| 212.7941176470588|    671.0|\n",
      "|            Balmain| 55|212.56363636363636|    712.0|\n",
      "|        North Bondi|180|206.68333333333334|    750.0|\n",
      "|             Bronte|144|203.70833333333334|    750.0|\n",
      "|        Queenscliff| 40|           201.925|    650.0|\n",
      "|          Lilyfield| 26|198.92307692307693|    701.0|\n",
      "|         Freshwater| 54| 198.5185185185185|    650.0|\n",
      "|           La Jolla| 52|197.82692307692307|    649.0|\n",
      "|     Marina del Rey|205| 196.6390243902439|    550.0|\n",
      "+-------------------+---+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most expensive popular cities\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select \n",
    "        city,\n",
    "        count(*) as ct,\n",
    "        avg(price) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df_final\n",
    "    group by city\n",
    "    order by avg(price) desc\n",
    "\"\"\").filter(\"ct > 25\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Define Continous and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = [\"bathrooms\", \\\n",
    "                       \"bedrooms\", \\\n",
    "                       \"security_deposit\", \\\n",
    "                       \"cleaning_fee\", \\\n",
    "                       \"extra_people\", \\\n",
    "                       \"number_of_reviews\", \\\n",
    "                       \"square_feet\", \\\n",
    "                       \"review_scores_rating\"]\n",
    "\n",
    "categorical_features = [\"room_type\", \\\n",
    "                        \"host_is_super_host\", \\\n",
    "                        \"cancellation_policy\", \\\n",
    "                        \"instant_bookable\", \\\n",
    "                        \"state\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Split Data into Training and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[training_dataset, validation_dataset] = df_final.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Continous Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "continuous_feature_assembler = VectorAssembler(inputCols=continuous_features, outputCol=\"unscaled_continuous_features\")\n",
    "\n",
    "continuous_feature_scaler = StandardScaler(inputCol=\"unscaled_continuous_features\", outputCol=\"scaled_continuous_features\", \\\n",
    "                                           withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: Categorical Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_feature_indexers = [StringIndexer(inputCol=x, \\\n",
    "                                              outputCol=\"{}_index\".format(x)) \\\n",
    "                                for x in categorical_features]\n",
    "\n",
    "categorical_feature_one_hot_encoders = [OneHotEncoder(inputCol=x.getOutputCol(), \\\n",
    "                                                      outputCol=\"oh_encoder_{}\".format(x.getOutputCol() )) \\\n",
    "                                        for x in categorical_feature_indexers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6**: Assemble our Features and Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols_lr = [x.getOutputCol() \\\n",
    "                   for x in categorical_feature_one_hot_encoders]\n",
    "feature_cols_lr.append(\"scaled_continuous_features\")\n",
    "\n",
    "feature_assembler_lr = VectorAssembler(inputCols=feature_cols_lr, \\\n",
    "                                       outputCol=\"features_lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7**: Train a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_4bea9edae088d627db1d\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression(featuresCol=\"features_lr\", \\\n",
    "                                     labelCol=\"price\", \\\n",
    "                                     predictionCol=\"price_prediction\", \\\n",
    "                                     maxIter=10, \\\n",
    "                                     regParam=0.3, \\\n",
    "                                     elasticNetParam=0.8)\n",
    "\n",
    "estimators_lr = \\\n",
    "  [continuous_feature_assembler, continuous_feature_scaler] \\\n",
    "  + categorical_feature_indexers + categorical_feature_one_hot_encoders \\\n",
    "  + [feature_assembler_lr] + [linear_regression]\n",
    "\n",
    "pipeline = Pipeline(stages=estimators_lr)\n",
    "\n",
    "pipeline_model = pipeline.fit(training_dataset)\n",
    "\n",
    "print(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8**:  Convert PipelineModel to PMML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n",
      "<PMML xmlns=\"http://www.dmg.org/PMML-4_3\" version=\"4.3\">\n",
      "\t<Header>\n",
      "\t\t<Application/>\n",
      "\t\t<Timestamp>2017-03-27T17:08:12Z</Timestamp>\n",
      "\t</Header>\n",
      "\t<DataDictionary>\n",
      "\t\t<DataField name=\"bathrooms\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"bedrooms\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"security_deposit\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"cleaning_fee\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"extra_people\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"number_of_reviews\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"square_feet\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"review_scores_rating\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t\t<DataField name=\"room_type\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"Entire home/apt\"/>\n",
      "\t\t\t<Value value=\"Private room\"/>\n",
      "\t\t\t<Value value=\"Shared room\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"host_is_super_host\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"0.0\"/>\n",
      "\t\t\t<Value value=\"1.0\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"cancellation_policy\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"strict\"/>\n",
      "\t\t\t<Value value=\"moderate\"/>\n",
      "\t\t\t<Value value=\"flexible\"/>\n",
      "\t\t\t<Value value=\"super_strict_30\"/>\n",
      "\t\t\t<Value value=\"no_refunds\"/>\n",
      "\t\t\t<Value value=\"super_strict_60\"/>\n",
      "\t\t\t<Value value=\"long_term\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"instant_bookable\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"0.0\"/>\n",
      "\t\t\t<Value value=\"1.0\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"state\" optype=\"categorical\" dataType=\"string\">\n",
      "\t\t\t<Value value=\"Other\"/>\n",
      "\t\t\t<Value value=\"NY\"/>\n",
      "\t\t\t<Value value=\"CA\"/>\n",
      "\t\t\t<Value value=\"Berlin\"/>\n",
      "\t\t\t<Value value=\"IL\"/>\n",
      "\t\t\t<Value value=\"TX\"/>\n",
      "\t\t\t<Value value=\"WA\"/>\n",
      "\t\t\t<Value value=\"DC\"/>\n",
      "\t\t\t<Value value=\"OR\"/>\n",
      "\t\t\t<Value value=\"London\"/>\n",
      "\t\t</DataField>\n",
      "\t\t<DataField name=\"price\" optype=\"continuous\" dataType=\"double\"/>\n",
      "\t</DataDictionary>\n",
      "\t<TransformationDictionary>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[0]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"bathrooms\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">2.0694178044699</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[1]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"bedrooms\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">1.1841578139669175</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[2]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"security_deposit\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.005528293625471707</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[3]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"cleaning_fee\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.023503907888529584</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[4]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"extra_people\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.053941703607268326</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[5]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"number_of_reviews\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.037033530093691217</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[6]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"square_feet\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.002693576320427388</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t\t<DerivedField name=\"scaled_continuous_features[7]\" optype=\"continuous\" dataType=\"double\">\n",
      "\t\t\t<Apply function=\"*\">\n",
      "\t\t\t\t<FieldRef field=\"review_scores_rating\"/>\n",
      "\t\t\t\t<Constant dataType=\"double\">0.11363684571655443</Constant>\n",
      "\t\t\t</Apply>\n",
      "\t\t</DerivedField>\n",
      "\t</TransformationDictionary>\n",
      "\t<RegressionModel functionName=\"regression\">\n",
      "\t\t<MiningSchema>\n",
      "\t\t\t<MiningField name=\"price\" usageType=\"target\"/>\n",
      "\t\t\t<MiningField name=\"bathrooms\"/>\n",
      "\t\t\t<MiningField name=\"bedrooms\"/>\n",
      "\t\t\t<MiningField name=\"security_deposit\"/>\n",
      "\t\t\t<MiningField name=\"cleaning_fee\"/>\n",
      "\t\t\t<MiningField name=\"extra_people\"/>\n",
      "\t\t\t<MiningField name=\"number_of_reviews\"/>\n",
      "\t\t\t<MiningField name=\"square_feet\"/>\n",
      "\t\t\t<MiningField name=\"review_scores_rating\"/>\n",
      "\t\t\t<MiningField name=\"room_type\"/>\n",
      "\t\t\t<MiningField name=\"host_is_super_host\"/>\n",
      "\t\t\t<MiningField name=\"cancellation_policy\"/>\n",
      "\t\t\t<MiningField name=\"instant_bookable\"/>\n",
      "\t\t\t<MiningField name=\"state\"/>\n",
      "\t\t</MiningSchema>\n",
      "\t\t<RegressionTable intercept=\"-34.92863985637842\">\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[0]\" coefficient=\"17.086657246509073\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[1]\" coefficient=\"22.136272333729234\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[2]\" coefficient=\"0.9746404215648721\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[3]\" coefficient=\"23.743529537063555\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[4]\" coefficient=\"2.1885813420248064\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[5]\" coefficient=\"-2.702884377424204\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[6]\" coefficient=\"3.0590826753812905\"/>\n",
      "\t\t\t<NumericPredictor name=\"scaled_continuous_features[7]\" coefficient=\"4.51103964412197\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Entire home/apt\" coefficient=\"27.953591583546153\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"room_type\" value=\"Private room\" coefficient=\"-11.84412411692917\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"host_is_super_host\" value=\"0.0\" coefficient=\"-5.518313707404658\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"strict\" coefficient=\"2.690406709014169\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"moderate\" coefficient=\"-4.820333309812547\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"flexible\" coefficient=\"0.0\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"super_strict_30\" coefficient=\"66.07552484327911\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"no_refunds\" coefficient=\"0.0\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"cancellation_policy\" value=\"super_strict_60\" coefficient=\"62.65987622321582\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"instant_bookable\" value=\"0.0\" coefficient=\"7.019590939009696\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Other\" coefficient=\"-11.107524809481783\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"NY\" coefficient=\"21.4058345812419\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"CA\" coefficient=\"12.697922398918772\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"Berlin\" coefficient=\"-49.63938639709832\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"IL\" coefficient=\"15.983445099508659\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"TX\" coefficient=\"32.22381075322937\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"WA\" coefficient=\"-8.022834073105122\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"DC\" coefficient=\"5.913735195331112\"/>\n",
      "\t\t\t<CategoricalPredictor name=\"state\" value=\"OR\" coefficient=\"-16.436721245351528\"/>\n",
      "\t\t</RegressionTable>\n",
      "\t</RegressionModel>\n",
      "</PMML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jpmml import toPMMLBytes\n",
    "\n",
    "model_bytes = toPMMLBytes(spark, training_dataset, pipeline_model)\n",
    "\n",
    "print(model_bytes.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push PMML to Live, Running Spark ML Model Server (Mutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 405: Method Not Allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-248316bdd1eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_url\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_headers\u001b[0m\u001b[0;34m,\u001b[0m                              \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpmmlBytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Should return Http Status 200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 582\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 405: Method Not Allowed"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'airbnb'\n",
    "version = '1'\n",
    "update_url = 'http://prediction-pmml-aws.demo.pipeline.io/update-pmml-model/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'application/xml'\n",
    "\n",
    "req = urllib.request.Request(update_url, \\\n",
    "                             headers=update_headers, \\\n",
    "                             data=model_bytes)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.status) # Should return Http Status 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "update_url = 'http://prediction-pmml-gcp.demo.pipeline.io/update-pmml/pmml_airbnb'\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'application/xml'\n",
    "\n",
    "req = urllib.request.Request(update_url, \\\n",
    "                             headers=update_headers, \\\n",
    "                             data=pmmlBytes)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.status) # Should return Http Status 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'airbnb'\n",
    "version = '1'\n",
    "evaluate_url = 'http://prediction-pmml-aws.demo.pipeline.io/evaluate-pmml-model/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "\n",
    "input_params = '{\"bathrooms\":5.0, \\\n",
    "                 \"bedrooms\":4.0, \\\n",
    "                 \"security_deposit\":175.00, \\\n",
    "                 \"cleaning_fee\":25.0, \\\n",
    "                 \"extra_people\":1.0, \\\n",
    "                 \"number_of_reviews\": 2.0, \\\n",
    "                 \"square_feet\": 250.0, \\\n",
    "                 \"review_scores_rating\": 2.0, \\\n",
    "                 \"room_type\": \"Entire home/apt\", \\\n",
    "                 \"host_is_super_host\": \"0.0\", \\\n",
    "                 \"cancellation_policy\": \"flexible\", \\\n",
    "                 \"instant_bookable\": \"1.0\", \\\n",
    "                 \"state\": \"CA\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = urllib.request.Request(evaluate_url, \\\n",
    "                             headers=evaluate_headers, \\\n",
    "                             data=encoded_input_params)\n",
    "\n",
    "resp = urllib.request.urlopen(req)\n",
    "\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Java-based Model (Simple Model, Mutable Deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "sourceBytes = '                                                      \\n\\\n",
    "  private String str;                                                \\n\\\n",
    "                                                                     \\n\\\n",
    "  public void initialize(Map<String, Object> args) {                 \\n\\\n",
    "  }                                                                  \\n\\\n",
    "                                                                     \\n\\\n",
    "  public Object predict(Map<String, Object> inputs) {                \\n\\\n",
    "      String id = (String)inputs.get(\"id\");                          \\n\\\n",
    "                                                                     \\n\\\n",
    "      return id.equals(\"21619\");                                     \\n\\\n",
    "  }                                                                  \\n\\\n",
    "'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* 001 */\n",
      "/* 002 */ private String str;\n",
      "/* 003 */\n",
      "/* 004 */ public void initialize(Map<String, Object> args) {\n",
      "/* 005 */ }\n",
      "/* 006 */\n",
      "/* 007 */ public Object predict(Map<String, Object> inputs) {\n",
      "/* 008 */   String id = (String)inputs.get(\"id\");\n",
      "/* 009 */\n",
      "/* 010 */   return id.equals(\"21619\");\n",
      "/* 011 */ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'java_equals'\n",
    "version = '1'\n",
    "\n",
    "update_url = 'http://prediction-java-aws.demo.pipeline.io/update-java/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'false'\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'java_equals'\n",
    "version = '1'\n",
    "\n",
    "evaluate_url = 'http://prediction-java-aws.demo.pipeline.io/evaluate-java/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"id\":\"21618\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return false "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'true'\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "namespace = 'default'\n",
    "model_name = 'java_equals'\n",
    "version = '1'\n",
    "evaluate_url = 'http://prediction-java-aws.demo.pipeline.io/evaluate-java/%s/%s/%s' % (namespace, model_name, version)\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"id\":\"21619\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Java Model (HttpClient Model, Mutable Deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "sourceBytes = '                                                         \\n\\\n",
    "  public Map<String, Object> data = new HashMap<String, Object>();      \\n\\\n",
    "                                                                        \\n\\\n",
    "  public void initialize(Map<String, Object> args) {                    \\n\\\n",
    "    data.put(\"url\", \"http://demo.pipeline.io:9040/prediction/\");        \\n\\\n",
    "  }                                                                     \\n\\\n",
    "                                                                        \\n\\\n",
    "  public Object predict(Map<String, Object> inputs) {                   \\n\\\n",
    "    try {                                                               \\n\\\n",
    "      String userId = (String)inputs.get(\"userId\");                     \\n\\\n",
    "      String itemId = (String)inputs.get(\"itemId\");                     \\n\\\n",
    "      String url = data.get(\"url\") + \"/\" + userId + \"/\" + itemId;       \\n\\\n",
    "                                                                        \\n\\\n",
    "      return org.apache.http.client.fluent.Request                      \\n\\\n",
    "        .Get(url)                                                       \\n\\\n",
    "        .execute()                                                      \\n\\\n",
    "        .returnContent();                                               \\n\\\n",
    "                                                                        \\n\\\n",
    "    } catch(Exception exc) {                                            \\n\\\n",
    "      System.out.println(exc);                                          \\n\\\n",
    "      throw exc;                                                        \\n\\\n",
    "    }                                                                   \\n\\\n",
    "  }                                                                     \\n\\\n",
    "'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* 001 */\n",
      "/* 002 */ public Map<String, Object> data = new HashMap<String, Object>();\n",
      "/* 003 */\n",
      "/* 004 */ public void initialize(Map<String, Object> args) {\n",
      "/* 005 */   data.put(\"url\", \"http://demo.pipeline.io:9040/prediction/\");\n",
      "/* 006 */ }\n",
      "/* 007 */\n",
      "/* 008 */ public Object predict(Map<String, Object> inputs) {\n",
      "/* 009 */   try {\n",
      "/* 010 */     String userId = (String)inputs.get(\"userId\");\n",
      "/* 011 */     String itemId = (String)inputs.get(\"itemId\");\n",
      "/* 012 */     String url = data.get(\"url\") + \"/\" + userId + \"/\" + itemId;\n",
      "/* 013 */\n",
      "/* 014 */     return org.apache.http.client.fluent.Request\n",
      "/* 015 */     .Get(url)\n",
      "/* 016 */     .execute()\n",
      "/* 017 */     .returnContent();\n",
      "/* 018 */\n",
      "/* 019 */   } catch(Exception exc) {\n",
      "/* 020 */     System.out.println(exc);\n",
      "/* 021 */     throw exc;\n",
      "/* 022 */   }\n",
      "/* 023 */ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "# Note:  Must have trailing '/'\n",
    "update_url = 'http://prediction-codegen-aws.demo.pipeline.io/update-codegen/%s/' % name\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "# Note:  Must have trailing '/'\n",
    "update_url = 'http://prediction-codegen-gcp.demo.pipeline.io/update-codegen/%s/' % name\n",
    "\n",
    "update_headers = {}\n",
    "update_headers['Content-type'] = 'text/plain'\n",
    "\n",
    "req = request.Request(\"%s\" % update_url, headers=update_headers, data=sourceBytes)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "generated_code = resp.read()\n",
    "print(generated_code.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "evaluate_url = 'http://prediction-codegen-aws.demo.pipeline.io/evaluate-codegen/%s' % name\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"userId\":\"21619\", \"itemId\":\"10006\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "name = 'codegen_httpclient'\n",
    "evaluate_url = 'http://prediction-codegen-gcp.demo.pipeline.io/evaluate-codegen/%s' % name\n",
    "\n",
    "evaluate_headers = {}\n",
    "evaluate_headers['Content-type'] = 'application/json'\n",
    "input_params = '{\"userId\":\"21619\", \"itemId\":\"10006\"}' \n",
    "encoded_input_params = input_params.encode('utf-8')\n",
    "\n",
    "req = request.Request(evaluate_url, headers=evaluate_headers, data=encoded_input_params)\n",
    "resp = request.urlopen(req)\n",
    "\n",
    "print(resp.read()) # Should return float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test and Compare Cloud Providers (AWS and Google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Performance Across Cloud Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetflixOSS Services [Dashboard](http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D) (Hystrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe width=100% height=500px src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "html = '<iframe width=100% height=500px src=\"http://hystrix.demo.pipeline.io/hystrix-dashboard/monitor/monitor.html?streams=%5B%7B%22name%22%3A%22Predictions%20-%20AWS%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-aws.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%2C%7B%22name%22%3A%22Predictions%20-%20GCP%22%2C%22stream%22%3A%22http%3A%2F%2Fturbine-gcp.demo.pipeline.io%2Fturbine.stream%22%2C%22auth%22%3A%22%22%2C%22delay%22%3A%22%22%7D%5D\">'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Load Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run JMeter Tests from Local Laptop (Limited by Laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Headless JMeter Tests from Training Clusters in Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spark ML - PMML - Airbnb\n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-airbnb-rc.yaml\n",
    "!kubectl create --context=gcpdemo -f /root/pipeline/loadtest.ml/loadtest-aws-airbnb-rc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Codegen - Java - Simple\n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-equals-rc.yaml\n",
    "!kubectl create --context=gcpdemo -f /root/pipeline/loadtest.ml/loadtest-aws-equals-rc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tensorflow AI - Tensorflow Serving - Simple \n",
    "!kubectl create --context=awsdemo -f /root/pipeline/loadtest.ml/loadtest-aws-minimal-rc.yaml\n",
    "!kubectl create --context=gcpdemo -f /root/pipeline/loadtest.ml/loadtest-aws-minimal-rc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Load Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kubectl delete --context=awsdemo rc loadtest-aws-airbnb\n",
    "!kubectl delete --context=gcpdemo rc loadtest-aws-airbnb\n",
    "!kubectl delete --context=awsdemo rc loadtest-aws-equals\n",
    "!kubectl delete --context=gcpdemo rc loadtest-aws-equals\n",
    "!kubectl delete --context=awsdemo rc loadtest-aws-minimal\n",
    "!kubectl delete --context=gcpdemo rc loadtest-aws-minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Deploy Tensorflow AI (Simple Model, Immutable Deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes [CLI](https://github.com/fluxcapacitor/pipeline/wiki/Kubernetes-Commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!kubectl rolling-update prediction-tensorflow --context=awsdemo --image-pull-policy=Always --image=fluxcapacitor/prediction-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl get pod --context=awsdemo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl rolling-update prediction-tensorflow --context=gcpdemo --image-pull-policy=Always --image=fluxcapacitor/prediction-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl get pod --context=gcpdemo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Q&A"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nbpresent": {
   "slides": {
    "0e6bc8b6-3cc5-496c-a34b-11d192afa91e": {
     "id": "0e6bc8b6-3cc5-496c-a34b-11d192afa91e",
     "prev": "aca594eb-585a-4405-b367-08bbe36b7e46",
     "regions": {
      "42084308-8543-4a24-918b-e452e3cba2e8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4d6901a2-06fc-4cc2-9168-0b4dd20436c3",
        "part": "whole"
       },
       "id": "42084308-8543-4a24-918b-e452e3cba2e8"
      }
     }
    },
    "10e8bf08-9a8f-4615-824e-4c015cb48051": {
     "id": "10e8bf08-9a8f-4615-824e-4c015cb48051",
     "prev": "6495f7a9-692a-452e-8a08-d34afb46a92a",
     "regions": {
      "f8860415-d84f-453f-b095-5a68337325ac": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de258cfb-7c21-40cf-b3ee-04228689eab0",
        "part": "whole"
       },
       "id": "f8860415-d84f-453f-b095-5a68337325ac"
      }
     }
    },
    "1ce58837-1471-4d9e-90bd-56c2482444bf": {
     "id": "1ce58837-1471-4d9e-90bd-56c2482444bf",
     "prev": "c121e0e8-a5cb-4e28-a578-f4246b9bc82e",
     "regions": {
      "53848919-ae68-4e10-b72b-40191b3af7bb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "023050ea-c894-4ffe-869f-2f27f03e524a",
        "part": "whole"
       },
       "id": "53848919-ae68-4e10-b72b-40191b3af7bb"
      }
     }
    },
    "32b2322c-9925-4e38-a692-05f3544576c3": {
     "id": "32b2322c-9925-4e38-a692-05f3544576c3",
     "prev": "10e8bf08-9a8f-4615-824e-4c015cb48051",
     "regions": {
      "251138f3-82aa-49e6-8e01-621ca02eb8fe": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b08fcd17-3ecd-4e73-a494-570728a3e129",
        "part": "whole"
       },
       "id": "251138f3-82aa-49e6-8e01-621ca02eb8fe"
      }
     }
    },
    "5e9dc412-fd7e-4a17-a5bd-1ac44cc9cdc6": {
     "id": "5e9dc412-fd7e-4a17-a5bd-1ac44cc9cdc6",
     "prev": "ae6895f7-9ad3-4ac7-a3a7-b23dddc95276",
     "regions": {
      "8a35ac4a-1620-48f4-90ec-3a9c5c577271": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "34e2d7fe-478c-4f42-aab6-0e17e4424576",
        "part": "whole"
       },
       "id": "8a35ac4a-1620-48f4-90ec-3a9c5c577271"
      }
     }
    },
    "6495f7a9-692a-452e-8a08-d34afb46a92a": {
     "id": "6495f7a9-692a-452e-8a08-d34afb46a92a",
     "prev": "5e9dc412-fd7e-4a17-a5bd-1ac44cc9cdc6",
     "regions": {
      "8c118309-a5f7-4970-8997-fa6d31be0cf9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a0dd485d-6cdf-4ccc-ba0c-60b2ed06bac7",
        "part": "whole"
       },
       "id": "8c118309-a5f7-4970-8997-fa6d31be0cf9"
      }
     }
    },
    "6a260c4b-6faa-456e-9680-dd7cbebe0933": {
     "id": "6a260c4b-6faa-456e-9680-dd7cbebe0933",
     "prev": "32b2322c-9925-4e38-a692-05f3544576c3",
     "regions": {
      "f65b7ebd-c02e-4088-95dc-8c90a5dffd09": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f5525416-d535-4377-bdf8-b91463fce353",
        "part": "whole"
       },
       "id": "f65b7ebd-c02e-4088-95dc-8c90a5dffd09"
      }
     }
    },
    "9c2c1cd9-1811-417c-8a27-edfef797f18b": {
     "id": "9c2c1cd9-1811-417c-8a27-edfef797f18b",
     "prev": "ee9cdb3f-6fb6-4497-ba5d-0fcddf43b8fd",
     "regions": {
      "867affd3-66d0-4835-bf85-a7b0e596d78e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ca731c95-6e39-4db8-a51c-f467a315616d",
        "part": "whole"
       },
       "id": "867affd3-66d0-4835-bf85-a7b0e596d78e"
      }
     }
    },
    "aca594eb-585a-4405-b367-08bbe36b7e46": {
     "id": "aca594eb-585a-4405-b367-08bbe36b7e46",
     "prev": "9c2c1cd9-1811-417c-8a27-edfef797f18b",
     "regions": {
      "22168c7b-acfd-4487-b57e-97aa88e5f3e8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ca8cd2ab-3693-4b40-90c0-d4b6adf8c20e",
        "part": "whole"
       },
       "id": "22168c7b-acfd-4487-b57e-97aa88e5f3e8"
      }
     }
    },
    "ae6895f7-9ad3-4ac7-a3a7-b23dddc95276": {
     "id": "ae6895f7-9ad3-4ac7-a3a7-b23dddc95276",
     "prev": "0e6bc8b6-3cc5-496c-a34b-11d192afa91e",
     "regions": {
      "1bf1c48a-1011-4992-8eaf-ef8e89a3d9c9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bd5629b7-e48e-42b7-ae26-38ed501f0246",
        "part": "whole"
       },
       "id": "1bf1c48a-1011-4992-8eaf-ef8e89a3d9c9"
      }
     },
     "theme": null
    },
    "c121e0e8-a5cb-4e28-a578-f4246b9bc82e": {
     "id": "c121e0e8-a5cb-4e28-a578-f4246b9bc82e",
     "prev": null,
     "regions": {
      "bf22675f-7d52-4ded-b588-7ddc477b17d6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fcb54439-1c2c-46ce-9d92-e77df43393db",
        "part": "whole"
       },
       "id": "bf22675f-7d52-4ded-b588-7ddc477b17d6"
      }
     }
    },
    "ee9cdb3f-6fb6-4497-ba5d-0fcddf43b8fd": {
     "id": "ee9cdb3f-6fb6-4497-ba5d-0fcddf43b8fd",
     "prev": "ff384e75-fefa-4966-a506-a12d5c4c770f",
     "regions": {
      "8d7dad4a-1d39-4ea7-8e9d-938bb9e7c00f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e4189884-f8d1-4d9a-827d-5ffe9bf7b21b",
        "part": "whole"
       },
       "id": "8d7dad4a-1d39-4ea7-8e9d-938bb9e7c00f"
      }
     }
    },
    "ff384e75-fefa-4966-a506-a12d5c4c770f": {
     "id": "ff384e75-fefa-4966-a506-a12d5c4c770f",
     "prev": "1ce58837-1471-4d9e-90bd-56c2482444bf",
     "regions": {
      "dd92502b-768b-431a-a5c3-6601da433340": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5dc02aa0-da66-4cce-b6f0-4e2253f8743c",
        "part": "whole"
       },
       "id": "dd92502b-768b-431a-a5c3-6601da433340"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
