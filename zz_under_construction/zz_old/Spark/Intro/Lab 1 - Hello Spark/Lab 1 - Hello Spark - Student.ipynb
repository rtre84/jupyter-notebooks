{"nbformat_minor": 0, "cells": [{"source": "## Lab 1 - Hello Spark\nThis Lab will show you how to work with Apache Spark using Python", "cell_type": "markdown", "metadata": {}}, {"source": "###Step 1 - Working with Spark Context\n###Check what version of Apache Spark is setup within this lab notebook.\n\nIn step 1 - Invoke the spark context and extract what version of the spark driver application is running.\n\nType\nsc.version", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "#Step 1 - Check spark version\n#Type:\n#sc.version\n\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "###Step 2 - Working with Resilient Distributed Datasets\n###Create multiple RDDs and return results\n\nIn Step 2 - Create RDD with numbers 1 to 10,\nExtract first line,\nExtract first 5 lines,\nCreate RDD with string \"Hello Spark\",\nExtract first line.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "#Step 2 - Create RDD of Numbers 1-10\n\n#Type: \n#x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n#x_nbr_rdd = sc.parallelize(x)\n\n", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 3, "cell_type": "code", "source": "#Step 2 - Extract first line\n\n#Type:\n#x_nbr_rdd.first()\n\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 4, "cell_type": "code", "source": "#Step 2 - Extract first 5 lines\n\n#Type:\n#x_nbr_rdd.take(5)\n\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 5, "cell_type": "code", "source": "#Step 2 - Create RDD String, Extract first line\n\n#Type:\n#y = [\"Hello Spark!\"]\n#y_str_rdd = sc.parallelize(y)\n#y_str_rdd.first()\n\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "###Step 3 - Working with Strings\nIn Step 3 - Create a larger string of words that include \"Hello\" and \"Spark\",\nMap the string into an RDD as a collection of words,\nextract the count of words \"Hello\" and \"Spark\" found in your RDD. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "#Step 3 - Create RDD String, Extract first line\n\n#type:\n#z = [\"Hello World!, Hello Universe!, I love Spark\"]\n#z_str_rdd = sc.parallelize(z)\n#z_str_rdd.first()\n\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 7, "cell_type": "code", "source": "#Step 3 - Create RDD with object for each word, Extract first 7 words\n\n#type:\n#z_str2_rdd = z_str_rdd.flatMap(lambda line: line.split(\" \"))\n#z_str2_rdd.take(7)\n\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 8, "cell_type": "code", "source": "#Step 3 - Count of \"Hello\" words\n\n#type:\n#z_str3_rdd = z_str2_rdd.filter(lambda line: \"Hello\" in line) \n#print \"The count of words 'Hello' in: \" + repr(z_str_rdd.first())\n#print \"Is: \" + repr(z_str3_rdd.count())\n\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 9, "cell_type": "code", "source": "#Step 3 - Count of \"Spark\" words\n#type\n#z_str4_rdd = z_str2_rdd.filter(lambda line: \"Spark\" in line) \n#print \"The count of words 'Spark' in: \" + repr(z_str_rdd.first())\n#print \"Is: \" + repr(z_str4_rdd.count())\n\n", "outputs": [], "metadata": {"scrolled": true, "collapsed": false, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}