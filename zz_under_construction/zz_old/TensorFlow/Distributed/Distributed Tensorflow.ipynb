{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Tensorflow\n",
    "\n",
    "\n",
    "![TensorFlowing](./files/tensors_flowing.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version_information extension is already loaded. To reload it, use:\n",
      "  %reload_ext version_information\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "2.7.11 64bit [GCC 4.2.1 (Apple Inc. build 5577)]"
        },
        {
         "module": "IPython",
         "version": "4.2.0"
        },
        {
         "module": "OS",
         "version": "Darwin 15.5.0 x86_64 i386 64bit"
        },
        {
         "module": "numpy",
         "version": "1.11.0"
        },
        {
         "module": "scipy",
         "version": "0.13.2"
        },
        {
         "module": "matplotlib",
         "version": "1.3.1"
        },
        {
         "module": "pandas",
         "version": "0.13.0"
        },
        {
         "module": "tensorflow",
         "version": "0.8.0"
        },
        {
         "module": "sklearn",
         "version": "0.14.1"
        },
        {
         "module": "skflow",
         "version": "The 'skflow' distribution was not found and is required by the application"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.11 64bit [GCC 4.2.1 (Apple Inc. build 5577)]</td></tr><tr><td>IPython</td><td>4.2.0</td></tr><tr><td>OS</td><td>Darwin 15.5.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.11.0</td></tr><tr><td>scipy</td><td>0.13.2</td></tr><tr><td>matplotlib</td><td>1.3.1</td></tr><tr><td>pandas</td><td>0.13.0</td></tr><tr><td>tensorflow</td><td>0.8.0</td></tr><tr><td>sklearn</td><td>0.14.1</td></tr><tr><td>skflow</td><td>The 'skflow' distribution was not found and is required by the application</td></tr><tr><td colspan='2'>Sat Jun 04 11:46:56 2016 PDT</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 2.7.11 64bit [GCC 4.2.1 (Apple Inc. build 5577)] \\\\ \\hline\n",
       "IPython & 4.2.0 \\\\ \\hline\n",
       "OS & Darwin 15.5.0 x86\\_64 i386 64bit \\\\ \\hline\n",
       "numpy & 1.11.0 \\\\ \\hline\n",
       "scipy & 0.13.2 \\\\ \\hline\n",
       "matplotlib & 1.3.1 \\\\ \\hline\n",
       "pandas & 0.13.0 \\\\ \\hline\n",
       "tensorflow & 0.8.0 \\\\ \\hline\n",
       "sklearn & 0.14.1 \\\\ \\hline\n",
       "skflow & The 'skflow' distribution was not found and is required by the application \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Sat Jun 04 11:46:56 2016 PDT} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 2.7.11 64bit [GCC 4.2.1 (Apple Inc. build 5577)]\n",
       "IPython 4.2.0\n",
       "OS Darwin 15.5.0 x86_64 i386 64bit\n",
       "numpy 1.11.0\n",
       "scipy 0.13.2\n",
       "matplotlib 1.3.1\n",
       "pandas 0.13.0\n",
       "tensorflow 0.8.0\n",
       "sklearn 0.14.1\n",
       "skflow The 'skflow' distribution was not found and is required by the application\n",
       "Sat Jun 04 11:46:56 2016 PDT"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, scipy, matplotlib, pandas, tensorflow, sklearn, skflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster\n",
    "\n",
    "To define a distributed computation in tensorflow we need to specify two kinds of jobs:\n",
    "\n",
    "- worker jobs\n",
    "- parameter server (ps) jobs\n",
    "\n",
    "Each **job** is defined by one ore more **tasks**. Each task is usually specified with a simple numerical index, i.e. `0,1,2,3, ..`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLUSTER_SPEC= \"\"\"\n",
    "{\n",
    "    'ps' : ['tensorflow0.pipeline.io:8888', 'tensorflow1.pipeline.io:8888'],\n",
    "    'worker' : [ 'tensorflow2.pipeline.io:8888','tensorflow3.pipeline.io:8888'],\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "cluster_def = ast.literal_eval(CLUSTER_SPEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ps': ['tensorflow0.pipeline.io:8888', 'tensorflow1.pipeline.io:8888'],\n",
       " 'worker': ['tensorflow2.pipeline.io:8888', 'tensorflow3.pipeline.io:8888']}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec = tf.train.ClusterSpec(cluster_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps', 'worker']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec.jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ps', ['tensorflow0.pipeline.io:8888', 'tensorflow1.pipeline.io:8888'])\n",
      "('worker', ['tensorflow2.pipeline.io:8888', 'tensorflow3.pipeline.io:8888'])\n"
     ]
    }
   ],
   "source": [
    "for job in spec.jobs:\n",
    "    print(job, spec.job_tasks(job))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workers = ['/job:worker/task:{}'.format(i) for i in range(len(cluster_def['worker']))]\n",
    "param_servers = ['/job:ps/task:{}'.format(i) for i in range(len(cluster_def['ps']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:worker/task:0', '/job:worker/task:1']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:ps/task:0', '/job:ps/task:1']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinning of Variables\n",
    "Each Variable is assigned to a specific device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u''"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = tf.Variable(\"local_cpu\")\n",
    "l.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can enforce the assigned device using the `tf.device` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/job:ps/task:1'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ps in param_servers:\n",
    "    with tf.device(ps):\n",
    "        v = tf.Variable(\"my_var\")\n",
    "v.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow Server\n",
    "\n",
    "The server is responsible to handle the actual communication. On each of the cluster's node we will spawn a simple gRPC Server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def launch_worker(job_name, task_id, cluster_def):\n",
    "    server = tf.train.Server(\n",
    "        cluster_def,\n",
    "        job_name=job_name,\n",
    "        task_index=task_id\n",
    "    )\n",
    "    server.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a Server\n",
    "\n",
    "to connect to _any_ server you can specify the 'target' of the session,direct ip:port of the server when creating a [Session](https://www.tensorflow.org/versions/r0.8/api_docs/python/client.html#Session) object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the server is generic and can assume either the role of parameter server or of worker.The Cluster configuration decides the role.\n",
    "\n",
    "![ps workers](./ps_workers.png)\n",
    "\n",
    "The best practice is to create a single Image launching the tensorflow worker. \n",
    "\n",
    "Environment variables then specify the exact role for the worker at run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### gRPC\n",
    "\n",
    "[gRPC](http://www.grpc.io) Is a Remote Procedure Call protocol based on [Protocol Buffers](https://developers.google.com/protocol-buffers/).\n",
    "\n",
    "\n",
    "Each object in tensorflow that has to be sent over the wire has a gRPC definition. \n",
    "\n",
    "1. Client figures out what variables need to be serialized to gRPC.\n",
    "1. Client makes the gRPC remote call to the Server and sends the values.\n",
    "1. If the Server accepts the call, the serialized tensors are de-serialized\n",
    "1. The Server runs the requested operation on the graph and all its dependencies\n",
    "1. The Server serializes the result and sends it back on the same connection to the Client\n",
    "1. The Client receives the results and deserializes.\n",
    "\n",
    "![gRPC Communicaton](./grpc_communication.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example of a gRPC declaration for the [Variable ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/variable.proto)\n",
    "\n",
    "\n",
    "```javascript\n",
    "syntax = \"proto3\";\n",
    "\n",
    "package tensorflow;\n",
    "\n",
    "// Protocol buffer representing a Variable.\n",
    "message VariableDef {\n",
    "  // Name of the variable tensor.\n",
    "  string variable_name = 1;\n",
    "\n",
    "  // Name of the initializer op.\n",
    "  string initializer_name = 2;\n",
    "\n",
    "  // Name of the snapshot tensor.\n",
    "  string snapshot_name = 3;\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "Each variable can then be serialized using the `to_proto` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable_name: \"Variable_24:0\"\n",
       "initializer_name: \"Variable_24/Assign\"\n",
       "snapshot_name: \"Variable_24/read:0\""
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v.to_proto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple reduce sum Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:worker/task:0\n",
      "/job:worker/task:1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "        \n",
    "    with tf.device('/job:ps/task:0'):\n",
    "        input_array = tf.placeholder(tf.int32, shape=[None])\n",
    "        final_result = tf.Variable(0)\n",
    "        \n",
    "    # divide the input across the cluster:\n",
    "    all_reduce = []\n",
    "    splitted = tf.split(0, len(workers), input_array)\n",
    "    for idx, (portion, worker) in enumerate(zip(splitted,workers)):\n",
    "        with tf.device(worker):\n",
    "           print(worker)\n",
    "           local_reduce = tf.reduce_sum(portion)\n",
    "           local_reduce = tf.Print(portion, [local_reduce], message=\"portion is\")\n",
    "           all_reduce.append(local_reduce)\n",
    "    \n",
    "    final_result = tf.reduce_sum(tf.pack(all_reduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can now run the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "\n",
    "with tf.Session(\"grpc://tensorflow3.pipeline.io:8888\", graph=graph, config=sess_config) as session:\n",
    "    result = session.run(final_result, feed_dict={ input_array: np.ones([1000]) }, options=run_options)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can also inspect any remote variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u''"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(\"grpc://tensorflow3.pipeline.io:8888\", graph=graph, config=sess_config) as session:\n",
    "    result = session.run(local_reduce, feed_dict={ input_array: np.ones([1000]) }, options=run_options)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
