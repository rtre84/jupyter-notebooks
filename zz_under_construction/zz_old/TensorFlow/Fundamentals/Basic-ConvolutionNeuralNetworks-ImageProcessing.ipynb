{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Convolutional Neural Network:  Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:  @Sam, please fill this in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note:  All datasets are available here:  /root/pipeline/datasets/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modules required for file download and extraction\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "def maybe_download(filename, url, force=False):\n",
    "  \"\"\"Download a file if not present.\"\"\"\n",
    "  if force or not os.path.exists('/root/pipeline/datasets/notmnist/' + filename):\n",
    "    filename, _ = urlretrieve(url + filename, '/root/pipeline/datasets/notmnist/' + filename)\n",
    "    print('\\nDownload complete for {}'.format(filename))\n",
    "  else:\n",
    "    print('File {} already present.'.format(filename))\n",
    "  return filename\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('{} already present - Skipping extraction of {}.'.format(root, filename))\n",
    "  else:\n",
    "    print('Extracting data for {}. This may take a while. Please wait.'.format(root))\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maybe_extract('/root/pipeline/datasets/notmnist/notMNIST_large.tar.gz')\n",
    "#maybe_extract('/root/pipeline/datasets/notmnist/notMNIST_small.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 64\r\n",
      "drwxr-xr-x 14 root 4096 Jun  4 13:50 \u001b[0m\u001b[01;34mdating\u001b[0m/\r\n",
      "drwxr-xr-x  3 root 4096 Jun  4 13:51 \u001b[01;34meigenface\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34memail\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34mgeo\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 Jun  4 14:52 \u001b[01;34mgraph\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34minception\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34mlsh\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34mmeetup\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34mmnist\u001b[0m/\r\n",
      "drwxr-xr-x  5 root 4096 Jun  4 13:49 \u001b[01;34mmovielens\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34mnlp\u001b[0m/\r\n",
      "drwxr-xr-x  3 root 4096 Jun  4 13:51 \u001b[01;34mnotmnist\u001b[0m/\r\n",
      "drwxr-xr-x  3 root 4096 May 31 05:40 \u001b[01;34mptb\u001b[0m/\r\n",
      "drwxr-xr-x  4 root 4096 Jun  4 13:51 \u001b[01;34mserving\u001b[0m/\r\n",
      "drwxr-xr-x  2 root 4096 May 31 05:40 \u001b[01;34msort\u001b[0m/\r\n",
      "drwxr-xr-x  4 root 4096 Jun  4 13:51 \u001b[01;34mtensorflow\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ll /root/pipeline/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempted to map inputs that were not found in graph_def: [input:0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-59700d3cccb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/root/pipeline/datasets/inception/classify_image_graph_def.pb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgraph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt_preprocessed\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict)\u001b[0m\n\u001b[0;32m    347\u001b[0m       raise ValueError(\n\u001b[0;32m    348\u001b[0m           \u001b[1;34m'Attempted to map inputs that were not found in graph_def: [%s]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m           % ', '.join(unused_input_keys))\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_elements\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempted to map inputs that were not found in graph_def: [input:0]"
     ]
    }
   ],
   "source": [
    "# Prepare input for the format expected by the graph\n",
    "t_input = tf.placeholder(np.float32, name='our_input') # define the input tensor\n",
    "imagenet_mean = 117.0\n",
    "t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n",
    "\n",
    "# Load graph and import into graph used by our session\n",
    "model_fn = '/root/pipeline/datasets/inception/classify_image_graph_def.pb'\n",
    "graph_def = tf.GraphDef.FromString(open(model_fn).read())\n",
    "tf.import_graph_def(graph_def, {'input':t_preprocessed})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Utility Functions to Display TensorBoard Inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for TF Graph visualization\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "  \n",
    "def rename_nodes(graph_def, rename_func):\n",
    "    res_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = res_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        n.name = rename_func(n.name)\n",
    "        for i, s in enumerate(n.input):\n",
    "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
    "    return res_def\n",
    "  \n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "  \n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "\n",
    "# Visualizing the network graph. Be sure expand the \"mixed\" nodes to see their \n",
    "# internal structure. We are going to visualize \"Conv2D\" nodes.\n",
    "tmp_def = rename_nodes(graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "#show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irrelevant code - only placed here to demo Inline TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = np.float32([1,4,6,4,1])\n",
    "k = np.outer(k, k)\n",
    "k5x5 = k[:,:,None,None]/k.sum()*np.eye(3, dtype=np.float32)\n",
    "\n",
    "def lap_split(img):\n",
    "    '''Split the image into lo and hi frequency components'''\n",
    "    with tf.name_scope('split'):\n",
    "        lo = tf.nn.conv2d(img, k5x5, [1,2,2,1], 'SAME')  # Blurred image -- low frequencies only\n",
    "        lo2 = tf.nn.conv2d_transpose(lo, k5x5*4, tf.shape(img), [1,2,2,1]) \n",
    "        hi = img-lo2 # hi is img with low frequencies removed\n",
    "    return lo, hi\n",
    "\n",
    "def lap_split_n(img, n):\n",
    "    '''Build Laplacian pyramid with n splits'''\n",
    "    levels = []\n",
    "    for i in xrange(n):\n",
    "        img, hi = lap_split(img)\n",
    "        levels.append(hi)\n",
    "    levels.append(img)\n",
    "    return levels[::-1] # List of images with lower and lower frequencies\n",
    "\n",
    "def lap_merge(levels):\n",
    "    '''Merge Laplacian pyramid'''\n",
    "    img = levels[0]\n",
    "    for hi in levels[1:]:\n",
    "        with tf.name_scope('merge'):\n",
    "            img = tf.nn.conv2d_transpose(img, k5x5*4, tf.shape(hi), [1,2,2,1]) + hi\n",
    "    return img # Reconstructed image, all frequencies added back together\n",
    "\n",
    "def normalize_std(img, eps=1e-10):\n",
    "    '''Normalize image by making its standard deviation = 1.0'''\n",
    "    with tf.name_scope('normalize'):\n",
    "        std = tf.sqrt(tf.reduce_mean(tf.square(img)))\n",
    "        return img/tf.maximum(std, eps)\n",
    "\n",
    "def lap_normalize(img, scale_n=4):\n",
    "    '''Perform the Laplacian pyramid normalization.'''\n",
    "    img = tf.expand_dims(img,0)\n",
    "    tlevels = lap_split_n(img, scale_n) # Split into frequencies\n",
    "    tlevels = map(normalize_std, tlevels) # Normalize each frequency band\n",
    "    out = lap_merge(tlevels) # Put image back together\n",
    "    return out[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Showing the lap_normalize graph with TensorBoard\n",
    "lap_graph = tf.Graph()\n",
    "with lap_graph.as_default():\n",
    "    lap_in = tf.placeholder(np.float32, name='lap_in')\n",
    "    lap_out = lap_normalize(lap_in)\n",
    "show_graph(lap_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
