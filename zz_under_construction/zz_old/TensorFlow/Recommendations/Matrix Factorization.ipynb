{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the following blog post: http://katbailey.github.io/post/matrix-factorization-with-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "num_users = 10\n",
    "rank = 10\n",
    "num_items = 10\n",
    "user_bias = 0\n",
    "\n",
    "# Initialize the matrix factors from random normals with mean 0. W will\n",
    "# represent users and H will represent items.\n",
    "W = tf.Variable(tf.truncated_normal([num_users, rank], stddev=0.2, mean=0), name=\"users\")\n",
    "H = tf.Variable(tf.truncated_normal([rank, num_items], stddev=0.2, mean=0), name=\"items\")\n",
    "\n",
    "# To the user matrix we add a bias column holding the bias of each user,\n",
    "# and another column of 1s to multiply the item bias by.\n",
    "W_plus_bias = tf.concat(1, [W, tf.convert_to_tensor(user_bias, dtype=tf.float32, name=\"user_bias\"), tf.ones((num_users,1), dtype=tf.float32, name=\"item_bias_ones\")])\n",
    "# To the item matrix we add a row of 1s to multiply the user bias by, and\n",
    "# a bias row holding the bias of each item.\n",
    "H_plus_bias = tf.concat(0, [H, tf.ones((1, num_items), name=\"user_bias_ones\", dtype=float32), tf.convert_to_tensor(item_bias, dtype=tf.float32, name=\"item_bias\")])\n",
    "# Multiply the factors to get our result as a dense matrix\n",
    "result = tf.matmul(W_plus_bias, H_plus_bias)\n",
    "\n",
    "# Now we just want the values represented by the pairs of user and item\n",
    "# indices for which we had known ratings. Unfortunately TensorFlow does not\n",
    "# yet support numpy-like indexing of tensors. See the issue for this at\n",
    "# https://github.com/tensorflow/tensorflow/issues/206 The workaround here\n",
    "# came from https://github.com/tensorflow/tensorflow/issues/418 and is a\n",
    "# little esoteric but in numpy this would just be done as follows:\n",
    "# result_values = result[user_indices, item_indices]\n",
    "result_values = tf.gather(tf.reshape(result, [-1]), user_indices * tf.shape(result)[1] + item_indices, name=\"extract_training_ratings\")\n",
    "\n",
    "# Same thing for the validation set ratings.\n",
    "result_values_val = tf.gather(tf.reshape(result, [-1]), user_indices_val * tf.shape(result)[1] + item_indices_val, name=\"extract_validation_ratings\")\n",
    "\n",
    "# Calculate the difference between the predicted ratings and the actual\n",
    "# ratings. The predicted ratings are the values obtained form the matrix\n",
    "# multiplication with the mean rating added on.\n",
    "diff_op = tf.sub(tf.add(result_values, mean_rating, name=\"add_mean\"), rating_values, name=\"raw_training_error\")\n",
    "diff_op_val = tf.sub(tf.add(result_values_val, mean_rating, name=\"add_mean_val\"), rating_values_val, name=\"raw_validation_error\")\n",
    "\n",
    "with tf.name_scope(\"training_cost\") as scope:\n",
    "    base_cost = tf.reduce_sum(tf.square(diff_op, name=\"squared_difference\"), name=\"sum_squared_error\")\n",
    "    # Add regularization.\n",
    "    regularizer = tf.mul(tf.add(tf.reduce_sum(tf.square(W)), tf.reduce_sum(tf.square(H))), lda, name=\"regularize\")\n",
    "    cost = tf.div(tf.add(base_cost, regularizer), num_ratings * 2, name=\"average_error\")\n",
    "\n",
    "with tf.name_scope(\"validation_cost\") as scope:\n",
    "    cost_val = tf.div(tf.reduce_sum(tf.square(diff_op_val, name=\"squared_difference_val\"), name=\"sum_squared_error_val\"), num_ratings_val * 2, name=\"average_error\")\n",
    "\n",
    "# Use an exponentially decaying learning rate.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.96, staircase=True)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Passing global_step to minimize() will increment it at each step so\n",
    "    # that the learning rate will be decayed at the specified intervals.\n",
    "    train_step = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "with tf.name_scope(\"training_accuracy\") as scope:\n",
    "  # Just measure the absolute difference against the threshold\n",
    "  # TODO: support percentage-based thresholds\n",
    "  good = tf.less(tf.abs(diff_op), threshold)\n",
    "\n",
    "  accuracy_tr = tf.div(tf.reduce_sum(tf.cast(good, tf.float32)), num_ratings)\n",
    "  accuracy_tr_summary = tf.scalar_summary(\"accuracy_tr\", accuracy_tr)\n",
    "\n",
    "with tf.name_scope(\"validation_accuracy\") as scope:\n",
    "  # Validation set accuracy:\n",
    "  good_val = tf.less(tf.abs(diff_op_val), threshold)\n",
    "  accuracy_val = tf.reduce_sum(tf.cast(good_val, tf.float32)) / num_ratings_val\n",
    "  accuracy_val_summary = tf.scalar_summary(\"accuracy_val\", accuracy_val)\n",
    "\n",
    "# Create a TensorFlow session and initialize variables.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Make sure summaries get written to the logs.\n",
    "summary_op = tf.merge_all_summaries()\n",
    "writer = tf.train.SummaryWriter(\"/tmp/recommender_logs\", sess.graph_def)\n",
    "\n",
    "# Run the graph and see how we're doing on every 500th iteration.\n",
    "for i in range(max_iter):\n",
    "    if i % 500 == 0:\n",
    "        res = sess.run([summary_op, accuracy_tr, accuracy_val, cost, cost_val])\n",
    "        summary_str = res[0]\n",
    "        acc_tr = res[1]\n",
    "        acc_val = res[2]\n",
    "        cost_ev = res[3]\n",
    "        cost_val_ev = res[4]\n",
    "        writer.add_summary(summary_str, i)\n",
    "        print(\"Training accuracy at step %s: %s\" % (i, acc_tr))\n",
    "        print(\"Validation accuracy at step %s: %s\" % (i, acc_val))\n",
    "        print(\"Training cost: %s\" % (cost_ev))\n",
    "        print(\"Validation cost: %s\" % (cost_val_ev))\n",
    "    else:\n",
    "        sess.run(train_step)\n",
    "\n",
    "with tf.name_scope(\"final_model\") as scope:\n",
    "    # At the end we want to get the final ratings matrix by adding the mean\n",
    "    # to the result matrix and doing any further processing required\n",
    "    add_mean_final = tf.add(result, mean_rating, name=\"add_mean_final\")\n",
    "    if result_processor == None:\n",
    "        final_matrix = add_mean_final\n",
    "    else:\n",
    "        final_matrix = result_processor(add_mean_final)\n",
    "    final_res = sess.run([final_matrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
