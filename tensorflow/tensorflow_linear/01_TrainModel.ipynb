{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pylab\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset TensorFlow Graph\n",
    "Useful in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Training and Test/Validation Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.random.rand(num_samples).astype(np.float32)\n",
    "print(x_train)\n",
    "\n",
    "noise = np.random.normal(scale=0.01, size=len(x_train))\n",
    "\n",
    "y_train = x_train * 0.1 + 0.3 + noise\n",
    "print(y_train)\n",
    "\n",
    "pylab.plot(x_train, y_train, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.random.rand(len(x_train)).astype(np.float32)\n",
    "print(x_test)\n",
    "\n",
    "noise = np.random.normal(scale=.01, size=len(x_train))\n",
    "\n",
    "y_test = x_test * 0.1 + 0.3 + noise\n",
    "print(y_test)\n",
    "\n",
    "pylab.plot(x_test, y_test, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    W = tf.get_variable(shape=[], name='weights')\n",
    "    print(W)\n",
    "\n",
    "    b = tf.get_variable(shape=[], name='bias')\n",
    "    print(b)\n",
    "\n",
    "    x_observed = tf.placeholder(shape=[None], \n",
    "                                dtype=tf.float32, \n",
    "                                name='x_observed')\n",
    "    print(x_observed)\n",
    "\n",
    "    y_pred = W * x_observed + b\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.025\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    y_observed = tf.placeholder(shape=[None], dtype=tf.float32, name='y_observed')\n",
    "    print(y_observed)\n",
    "\n",
    "    loss_op = tf.reduce_mean(tf.square(y_pred - y_observed))\n",
    "    optimizer_op = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    \n",
    "    train_op = optimizer_op.minimize(loss_op)  \n",
    "\n",
    "    print(\"Loss Scalar: \", loss_op)\n",
    "    print(\"Optimizer Op: \", optimizer_op)\n",
    "    print(\"Train Op: \", train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Initialize Variables (Weights and Bias)\n",
    "The goal is to learn more accurate Weights and Bias during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    print(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init_op)\n",
    "print(\"Initial random W: %f\" % sess.run(W))\n",
    "print(\"Initial random b: %f\" % sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Accuracy of Pre-Training, Initial Random Variables\n",
    "We want this to be close to 0, but it's relatively far away.  This is why we train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(x, y):\n",
    "    return sess.run(loss_op, feed_dict={x_observed: x, y_observed: y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss Summary Operations for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_summary_scalar_op = tf.summary.scalar('loss', loss_op)\n",
    "loss_summary_merge_all_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "version = int(datetime.now().strftime(\"%s\"))\n",
    "\n",
    "train_summary_writer = tf.summary.FileWriter('/root/tensorboard/linear/cpu/%s/train' % version, \n",
    "                                            graph=tf.get_default_graph())\n",
    "\n",
    "test_summary_writer = tf.summary.FileWriter('/root/tensorboard/linear/cpu/%s/test' % version,\n",
    "                                            graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    max_steps = 401\n",
    "    for step in range(max_steps):\n",
    "        if (step < max_steps - 1):\n",
    "            test_summary_log, _ = sess.run([loss_summary_merge_all_op, loss_op], feed_dict={x_observed: x_test, y_observed: y_test})\n",
    "            train_summary_log, _ = sess.run([loss_summary_merge_all_op, train_op], feed_dict={x_observed: x_train, y_observed: y_train})\n",
    "        else:  \n",
    "            test_summary_log, _ = sess.run([loss_summary_merge_all_op, loss_op], feed_dict={x_observed: x_test, y_observed: y_test})\n",
    "            train_summary_log, _ = sess.run([loss_summary_merge_all_op, train_op], feed_dict={x_observed: x_train, y_observed: y_train}, \n",
    "                                            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), \n",
    "                                            run_metadata=run_metadata)\n",
    "        if step % 10 == 0:\n",
    "            print(step, sess.run([W, b]))\n",
    "            train_summary_writer.add_summary(train_summary_log, step)\n",
    "            train_summary_writer.flush()\n",
    "            test_summary_writer.add_summary(test_summary_log, step)\n",
    "            test_summary_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.plot(x_train, y_train, '.', label=\"target\")\n",
    "pylab.plot(x_train, sess.run(y_pred, \n",
    "                             feed_dict={x_observed: x_train, \n",
    "                                        y_observed: y_train}), \n",
    "           \".\", \n",
    "           label=\"predicted\")\n",
    "pylab.legend()\n",
    "pylab.ylim(0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View `loss` in Tensorboard\n",
    "Navigate to the `Scalars` and `Graphs` tab at this URL:\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "x_observed = graph.get_tensor_by_name('x_observed:0')\n",
    "y_pred = graph.get_tensor_by_name('add:0')\n",
    "\n",
    "tensor_info_x_observed = utils.build_tensor_info(x_observed)\n",
    "print(tensor_info_x_observed)\n",
    "\n",
    "tensor_info_y_pred = utils.build_tensor_info(y_pred)\n",
    "print(tensor_info_y_pred)\n",
    "\n",
    "prediction_signature = signature_def_utils.build_signature_def(inputs = \n",
    "                {'x_observed': tensor_info_x_observed}, \n",
    "                outputs = {'y_pred': tensor_info_y_pred}, \n",
    "                method_name = signature_constants.PREDICT_METHOD_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "rm -rf ./export\n",
    "rm -rf ./variables\n",
    "rm saved_model.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "fully_optimized_saved_model_path = './export'\n",
    "print(fully_optimized_saved_model_path)\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(fully_optimized_saved_model_path)\n",
    "builder.add_meta_graph_and_variables(sess, \n",
    "                                     [tag_constants.SERVING],\n",
    "                                     signature_def_map={'predict':prediction_signature,                                     \n",
    "signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature}, \n",
    "                                     clear_devices=True,\n",
    ")\n",
    "\n",
    "builder.save(as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l ./export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mv ./export/* .\n",
    "rm -rf ./export/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PioBundle(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform_request(self,\n",
    "                          request):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        import json\n",
    "        import numpy as np\n",
    "\n",
    "        request_str = request.decode('utf-8')\n",
    "        request_json = json.loads(request_str)\n",
    "        request_np = np.asarray([request_json['x_observed']])\n",
    "\n",
    "        return request_np\n",
    "    \n",
    "    \n",
    "    def transform_response(self,\n",
    "                           response):\n",
    "        import json\n",
    "        return json.dumps({\"y_pred\": response.tolist()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "pio_bundle = PioBundle()\n",
    "\n",
    "pio_bundle_pkl_path = 'pio_bundle.pkl'\n",
    "\n",
    "with open(pio_bundle_pkl_path, 'wb') as fh:\n",
    "    pickle.dump(pio_bundle, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l pio_bundle.pkl \n",
    "ls -l saved_model.pb \n",
    "ls -l variables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
